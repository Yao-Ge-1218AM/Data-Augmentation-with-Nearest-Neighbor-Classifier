{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MWZCW6DXWvYu"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/cuhksz-nlp/SANER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L16aDwoJvpww"
      },
      "source": [
        "2023 Jan: torch==1.5.1\n",
        "2023 Nov: torch==2.1.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "laeKjPfaJ-mq"
      },
      "outputs": [],
      "source": [
        "!pip install torch==2.2.1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install hunggingface =="
      ],
      "metadata": {
        "id": "3fYp5L-zuHuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "agdhDNfn8bFj"
      },
      "outputs": [],
      "source": [
        "!pip install spacy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AEI06Q9s9Ox3"
      },
      "outputs": [],
      "source": [
        "!pip install tqdm==4.48.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rDYA22LD9S1u"
      },
      "outputs": [],
      "source": [
        "!pip install fastNLP==0.5"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OdSLyWaKW524"
      },
      "outputs": [],
      "source": [
        "!pip install word2vec==0.9.4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_OCv0n5nW7dd",
        "outputId": "500ea4e5-05f7-4c6c-e74e-69dd28c9599d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-07-31 15:43:03--  https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz\n",
            "Resolving s3.amazonaws.com (s3.amazonaws.com)... 16.182.65.8, 3.5.0.63, 52.217.33.102, ...\n",
            "Connecting to s3.amazonaws.com (s3.amazonaws.com)|16.182.65.8|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1242874899 (1.2G) [application/x-tar]\n",
            "Saving to: ‘bert-large-cased.tar.gz’\n",
            "\n",
            "bert-large-cased.ta 100%[===================>]   1.16G  30.7MB/s    in 41s     \n",
            "\n",
            "2024-07-31 15:43:44 (29.1 MB/s) - ‘bert-large-cased.tar.gz’ saved [1242874899/1242874899]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SAld6sfNW7X5",
        "outputId": "bad4148b-f3a9-4a60-8a52-86297ba348c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "bert_config.json\n",
            "pytorch_model.bin\n"
          ]
        }
      ],
      "source": [
        "!tar -xzvf /content/bert-large-cased.tar.gz"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xAajttG2wugl"
      },
      "source": [
        "try biobert and clinical-bert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mZNtyb-1xZ1l"
      },
      "outputs": [],
      "source": [
        "!wget http://nlp.dmis.korea.edu/projects/biobert-2020-checkpoints/biobert_large_v1.1_pubmed.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mzt7pMJE0Nu4"
      },
      "outputs": [],
      "source": [
        "!tar -xzvf /content/biobert_large_v1.1_pubmed.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PsMonQhwRGCO"
      },
      "outputs": [],
      "source": [
        "!wget -O umlsbert.tar.xz https://www.dropbox.com/s/kziiuyhv9ile00s/umlsbert.tar.xz?dl=0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "57RU-vriRIMX"
      },
      "outputs": [],
      "source": [
        "!tar -xvf umlsbert.tar.xz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJgqVZKPzfh9",
        "outputId": "62e8da07-a152-4f61-d00d-64cd9c58af6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JzW5TUczWIg"
      },
      "outputs": [],
      "source": [
        "!gdown --id '11ctw2nw0NQ811_4uBA86670yPk_YgsUe'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mJMjx4eP-ZwW"
      },
      "outputs": [],
      "source": [
        "!gdown --id '1CG2nEpfPm3rWVhEjr-dkS7DWENmxSl8v'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1MR8wdLoW90C"
      },
      "source": [
        "**[NOTE1]** After decompression \"bert-large-cased.tar.gz\", we will get two files: \"bert_config.json\" and \"pytorch_model.bin\", but we don't have the file \"vocab.txt\". So we need to:\n",
        "\n",
        "1. Create a new folder under the *SANER/data* folder and name it \"bert-large-cased\";\n",
        "\n",
        "2. Upload the file \"vocab.txt\" into this bert folder;\n",
        "\n",
        "3. Move files \"bert_config.json\" and \"pytorch_model.bin\" to this bert folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZFT8GyRAYtw5"
      },
      "outputs": [],
      "source": [
        "cd SANER/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jluvX0JvYv3x"
      },
      "source": [
        "**[NOTE2]** If we want to run SANER (itself), we also need to:\n",
        "\n",
        "1. Upload the file \"glove.100\" into the folder SANER/data\n",
        "\n",
        "2. Create a new folder under the SANER folder and name it \"log\"\n",
        "\n",
        "3. Change the path in \"train_bert_elmo_en.py\" line 122 - line 136 with the code in cell below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HHQ6SV-OxSZ6"
      },
      "outputs": [],
      "source": [
        "!mkdir log"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GNQeBWyLWmuB"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/SANER/data/bert-large-cased/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W_KNkfG893pT"
      },
      "outputs": [],
      "source": [
        "!mv /content/bert_config.json /content/SANER/data/bert-large-cased/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bizHVh8U99CQ"
      },
      "outputs": [],
      "source": [
        "!mv /content/pytorch_model.bin /content/SANER/data/bert-large-cased/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XPVkk0Vs-OHN"
      },
      "outputs": [],
      "source": [
        "!mv /content/vocab.txt /content/SANER/data/bert-large-cased/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7u7_lBfe-P3V"
      },
      "outputs": [],
      "source": [
        "!mv /content/glove.100d.txt /content/SANER/data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V7uKJh1YqU3o",
        "outputId": "996dc535-17c2-432d-b378-c5b726459be5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ki46-12WvevW",
        "outputId": "19665b25-fa05-45d9-d0b1-5bafdff885aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "drive.mount(\"/content/drive\", force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ingqHKN7xHfs"
      },
      "source": [
        "/content/SANER/train_bert_elmo_en.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z55XAWrCfdQ3"
      },
      "outputs": [],
      "source": [
        "!cp /content/drive/MyDrive/glove.100d.txt /content/SANER/data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5qisl5SSX9RI"
      },
      "outputs": [],
      "source": [
        "paths = {\n",
        "    \"train\": \"../SANER/data/{}/train.txt\".format(dataset),\n",
        "    \"test\": \"../SANER/data/{}/test.txt\".format(dataset),\n",
        "    \"dev\": \"../SANER/data/{}/dev.txt\".format(dataset)\n",
        "}\n",
        "data = WNUT_17NERPipe(encoding_type=encoding_type).process_from_file(paths)\n",
        "\n",
        "dict_save_path = os.path.join(\"../SANER/data/{}/data.pth\".format(dataset))\n",
        "context_dict, context_word2id, context_id2word = get_neighbor_for_vocab(\n",
        "    data.get_vocab('words').word2idx, glove_path, dict_save_path\n",
        ")\n",
        "\n",
        "train_feature_data, dev_feature_data, test_feature_data = build_instances(\n",
        "    \"../SANER/data/{}\".format(dataset), context_num, context_dict\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UqLsO6YspHcu"
      },
      "source": [
        "**[NOTE3]** Now we can run SANER.\n",
        "\n",
        "Some tips:\n",
        "\n",
        "1. The default folder for input data (train/dev/test) is /SANER/data/sampleSet\n",
        "\n",
        "2. There is a special point, we need to leave two blank lines at the end of train/dev/test, otherwise an error will be reported.\n",
        "\n",
        "3. If we want to run again totaly, we need to delete two folders: \"SANER/caches\" and \"SANER/ckpt\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B26qoTzhe5t7"
      },
      "source": [
        "**bug1:** one possible error:         _VF._pack_padded_sequence(input, lengths.cpu(), batch_first)\n",
        "\n",
        "/usr/local/lib/python3.10/dist-packages/torch/nn/utils/rnn.py\n",
        "\n",
        "line 264"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M9WNuatWHnpn"
      },
      "outputs": [],
      "source": [
        "!unzip /content/elmo_en_Original.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE88GZGRwHIX"
      },
      "outputs": [],
      "source": [
        "!unzip /content/drive/MyDrive/elmo_en_Original.zip -d /content/SANER/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oympkN6SXOsk"
      },
      "source": [
        "**bug2:** *line* 68:         model_dir_or_name = \"/content/SANER/elmo_en_Original/\"\n",
        "\n",
        "/content/SANER/fastNLP/embeddings/elmo_embedding.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2O8WGO-aWTc"
      },
      "source": [
        "**bug3:** module 'numpy' has no attribute 'float'. ???*italicized text*\n",
        "\n",
        "/usr/local/lib/python3.10/dist-packages/word2vec/wordvectors.py\n",
        "\n",
        "line 237，244\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyI_NvkO_jK4"
      },
      "source": [
        "**bug4:** embed.weight.data[len(new_word_piece_vocab)] = original_embed[self.tokenzier.vocab[token]]\n",
        "IndexError: index 29627 is out of bounds for dimension 0 with size 28996\n",
        "\n",
        "尝试换了vocab.txt, size = 213,450 bytes\n",
        "\n",
        "/content/SANER/fastNLP/embeddings/bert_embedding.py\n",
        "\n",
        "line 314:         self.word_to_wordpieces = np.array(word_to_wordpieces, dtype=object)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Kfz_U-Qjss5"
      },
      "source": [
        "**Predictions:**\n",
        "\n",
        "/content/SANER/fastNLP/core/metrics.py\n",
        "\n",
        "metrics: line 689,找到prediction\n",
        "\n",
        "last epoch才存：\n",
        "\n",
        "open_count = 0\n",
        "\n",
        "global open_count\n",
        "open_count += 1\n",
        "\n",
        "if(open_count>11195):\n",
        "  with open(\"/content/SANER/predictions-cdr-gpt-parents.txt\", \"a\") as wf:\n",
        "    wf.write(' '.join(pred_str_tags) + \"\\n\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "open_count>11195, 11195x49 = 548555, cdr\n"
      ],
      "metadata": {
        "id": "HHoltmtnjQ4m"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5gnv_F24fdgs"
      },
      "source": [
        "open_count>821, 821x49=40229, mimic3\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBQU4j4og80s"
      },
      "source": [
        "open_count>536, 536x49=26264, impacts\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88SytEAAuINw"
      },
      "source": [
        "open_count>156, 156x49=7644, blood pressure; 269x45=12105"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk-jtLE7QgjH"
      },
      "source": [
        "open_count>33171, 110x49=1625379, 1634119,medmentions"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "200，200x49，ncbi"
      ],
      "metadata": {
        "id": "m7f7xYvbTFXo"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD9wE4mZforT"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/SANER.zip /content/SANER/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-e3lGuNyheDE"
      },
      "outputs": [],
      "source": [
        "!cp /content/SANER.zip /content/drive/MyDrive/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "a9y1ODdC3yro",
        "outputId": "d95c3b9c-53ed-4075-e749-26b8c7d6fb09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/drive/MyDrive/SANER.zip\n",
            "   creating: /content/SANER/content/SANER/\n",
            "   creating: /content/SANER/content/SANER/modules/\n",
            "  inflating: /content/SANER/content/SANER/modules/utils.py  \n",
            "  inflating: /content/SANER/content/SANER/modules/transformer.py  \n",
            "  inflating: /content/SANER/content/SANER/modules/pipe.py  \n",
            "  inflating: /content/SANER/content/SANER/modules/relative_transformer.py  \n",
            "  inflating: /content/SANER/content/SANER/modules/callbacks.py  \n",
            " extracting: /content/SANER/content/SANER/modules/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/modules/TransformerEmbedding.py  \n",
            "  inflating: /content/SANER/content/SANER/utils_token_level_task.py  \n",
            "   creating: /content/SANER/content/SANER/data/\n",
            "   creating: /content/SANER/content/SANER/data/bert-large-cased/\n",
            "  inflating: /content/SANER/content/SANER/data/bert-large-cased/bert_config.json  \n",
            "  inflating: /content/SANER/content/SANER/data/bert-large-cased/pytorch_model.bin  \n",
            "  inflating: /content/SANER/content/SANER/data/bert-large-cased/vocab.txt  \n",
            "   creating: /content/SANER/content/SANER/data/W16/\n",
            "  inflating: /content/SANER/content/SANER/data/W16/train.txt  \n",
            "  inflating: /content/SANER/content/SANER/data/W16/dev.txt  \n",
            "  inflating: /content/SANER/content/SANER/data/W16/test.txt  \n",
            "   creating: /content/SANER/content/SANER/data/sampleSet/\n",
            "  inflating: /content/SANER/content/SANER/data/sampleSet/data.pth  \n",
            "  inflating: /content/SANER/content/SANER/data/sampleSet/train.txt  \n",
            "  inflating: /content/SANER/content/SANER/data/sampleSet/dev.txt  \n",
            "  inflating: /content/SANER/content/SANER/data/sampleSet/test.txt  \n",
            "  inflating: /content/SANER/content/SANER/data/glove.100d.txt  \n",
            "  inflating: /content/SANER/content/SANER/data/saner.md  \n",
            "   creating: /content/SANER/content/SANER/data/WB/\n",
            "  inflating: /content/SANER/content/SANER/data/WB/train.txt  \n",
            "  inflating: /content/SANER/content/SANER/data/WB/dev.txt  \n",
            "  inflating: /content/SANER/content/SANER/data/WB/test.txt  \n",
            "   creating: /content/SANER/content/SANER/data/W17/\n",
            "  inflating: /content/SANER/content/SANER/data/W17/train.txt  \n",
            "  inflating: /content/SANER/content/SANER/data/W17/dev.txt  \n",
            "  inflating: /content/SANER/content/SANER/data/W17/test.txt  \n",
            "  inflating: /content/SANER/content/SANER/data_preprocess.py  \n",
            "   creating: /content/SANER/content/SANER/fastNLP/\n",
            "   creating: /content/SANER/content/SANER/fastNLP/modules/\n",
            "   creating: /content/SANER/content/SANER/fastNLP/modules/encoder/\n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/star_transformer.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/transformer.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/bert.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/lstm.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/variational_rnn.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/attention.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/_elmo.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/char_encoder.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/conv_maxpool.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/pooling.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/encoder/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/dropout.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/utils.py  \n",
            "   creating: /content/SANER/content/SANER/fastNLP/modules/decoder/\n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/decoder/mlp.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/decoder/utils.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/decoder/crf.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/decoder/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/modules/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/doc_utils.py  \n",
            "   creating: /content/SANER/content/SANER/fastNLP/core/\n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/callback.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/utils.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/batch.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/sampler.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/_parallel_utils.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/vocabulary.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/dataset.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/field.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/optimizer.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/dist_trainer.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/const.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/losses.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/metrics.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/_logger.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/trainer.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/instance.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/predictor.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/core/tester.py  \n",
            "   creating: /content/SANER/content/SANER/fastNLP/io/\n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/file_reader.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/utils.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/embed_loader.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/file_utils.py  \n",
            "   creating: /content/SANER/content/SANER/fastNLP/io/pipe/\n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/pipe/utils.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/pipe/qa.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/pipe/pipe.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/pipe/coreference.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/pipe/classification.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/pipe/cws.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/pipe/conll.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/pipe/summarization.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/pipe/matching.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/pipe/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/data_bundle.py  \n",
            "   creating: /content/SANER/content/SANER/fastNLP/io/loader/\n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/loader.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/qa.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/json.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/coreference.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/classification.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/cws.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/conll.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/csv.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/summarization.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/matching.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/loader/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/model_io.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/io/__init__.py  \n",
            "   creating: /content/SANER/content/SANER/fastNLP/embeddings/\n",
            "  inflating: /content/SANER/content/SANER/fastNLP/embeddings/char_embedding.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/embeddings/utils.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/embeddings/bert_embedding.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/embeddings/embedding.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/embeddings/elmo_embedding.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/embeddings/contextual_embedding.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/embeddings/stack_embedding.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/embeddings/static_embedding.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/embeddings/__init__.py  \n",
            "   creating: /content/SANER/content/SANER/fastNLP/models/\n",
            "  inflating: /content/SANER/content/SANER/fastNLP/models/star_transformer.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/models/base_model.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/models/bert.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/models/biaffine_parser.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/models/snli.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/models/sequence_labeling.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/models/cnn_text_classification.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/models/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/fastNLP/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/run_cn.py  \n",
            "  inflating: /content/SANER/content/SANER/train_bert_elmo_en.py  \n",
            "  inflating: /content/SANER/content/SANER/run_token_level_classification.py  \n",
            "  inflating: /content/SANER/content/SANER/README.md  \n",
            "   creating: /content/SANER/content/SANER/.ipynb_checkpoints/\n",
            " extracting: /content/SANER/content/SANER/requirements.txt  \n",
            "   creating: /content/SANER/content/SANER/elmo_en_Original/\n",
            "  inflating: /content/SANER/content/SANER/elmo_en_Original/char.dic  \n",
            "  inflating: /content/SANER/content/SANER/elmo_en_Original/elmo_2x4096_512_2048cnn_2xhighway_options.json  \n",
            "  inflating: /content/SANER/content/SANER/elmo_en_Original/elmo_2x4096_512_2048cnn_2xhighway_weights.pkl  \n",
            "   creating: /content/SANER/content/SANER/.git/\n",
            "   creating: /content/SANER/content/SANER/.git/hooks/\n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/applypatch-msg.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/pre-push.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/commit-msg.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/prepare-commit-msg.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/pre-commit.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/pre-rebase.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/pre-applypatch.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/update.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/post-update.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/push-to-checkout.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/pre-merge-commit.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/fsmonitor-watchman.sample  \n",
            "  inflating: /content/SANER/content/SANER/.git/hooks/pre-receive.sample  \n",
            "   creating: /content/SANER/content/SANER/.git/objects/\n",
            "   creating: /content/SANER/content/SANER/.git/objects/pack/\n",
            "  inflating: /content/SANER/content/SANER/.git/objects/pack/pack-080728ddc72fc63a4f30b028a48dce3ab0938061.idx  \n",
            "  inflating: /content/SANER/content/SANER/.git/objects/pack/pack-080728ddc72fc63a4f30b028a48dce3ab0938061.pack  \n",
            "   creating: /content/SANER/content/SANER/.git/objects/info/\n",
            "  inflating: /content/SANER/content/SANER/.git/config  \n",
            "  inflating: /content/SANER/content/SANER/.git/description  \n",
            "   creating: /content/SANER/content/SANER/.git/branches/\n",
            "   creating: /content/SANER/content/SANER/.git/logs/\n",
            "   creating: /content/SANER/content/SANER/.git/logs/refs/\n",
            "   creating: /content/SANER/content/SANER/.git/logs/refs/heads/\n",
            "  inflating: /content/SANER/content/SANER/.git/logs/refs/heads/master  \n",
            "   creating: /content/SANER/content/SANER/.git/logs/refs/remotes/\n",
            "   creating: /content/SANER/content/SANER/.git/logs/refs/remotes/origin/\n",
            "  inflating: /content/SANER/content/SANER/.git/logs/refs/remotes/origin/HEAD  \n",
            "  inflating: /content/SANER/content/SANER/.git/logs/HEAD  \n",
            "   creating: /content/SANER/content/SANER/.git/refs/\n",
            "   creating: /content/SANER/content/SANER/.git/refs/heads/\n",
            " extracting: /content/SANER/content/SANER/.git/refs/heads/master  \n",
            "   creating: /content/SANER/content/SANER/.git/refs/tags/\n",
            "   creating: /content/SANER/content/SANER/.git/refs/remotes/\n",
            "   creating: /content/SANER/content/SANER/.git/refs/remotes/origin/\n",
            " extracting: /content/SANER/content/SANER/.git/refs/remotes/origin/HEAD  \n",
            "  inflating: /content/SANER/content/SANER/.git/packed-refs  \n",
            " extracting: /content/SANER/content/SANER/.git/HEAD  \n",
            "   creating: /content/SANER/content/SANER/.git/info/\n",
            "  inflating: /content/SANER/content/SANER/.git/info/exclude  \n",
            "  inflating: /content/SANER/content/SANER/.git/index  \n",
            "   creating: /content/SANER/content/SANER/ZEN/\n",
            "  inflating: /content/SANER/content/SANER/ZEN/file_utils.py  \n",
            "  inflating: /content/SANER/content/SANER/ZEN/tokenization.py  \n",
            "  inflating: /content/SANER/content/SANER/ZEN/ngram_utils.py  \n",
            "  inflating: /content/SANER/content/SANER/ZEN/optimization.py  \n",
            "  inflating: /content/SANER/content/SANER/ZEN/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/ZEN/modeling.py  \n",
            "  inflating: /content/SANER/content/SANER/data_process.py  \n",
            "  inflating: /content/SANER/content/SANER/LICENSE  \n",
            "  inflating: /content/SANER/content/SANER/train_zen_cn.py  \n",
            "   creating: /content/SANER/content/SANER/log/\n",
            "  inflating: /content/SANER/content/SANER/get_context.py  \n",
            "   creating: /content/SANER/content/SANER/models/\n",
            "  inflating: /content/SANER/content/SANER/models/TENER.py  \n",
            " extracting: /content/SANER/content/SANER/models/__init__.py  \n",
            "  inflating: /content/SANER/content/SANER/run.py  \n"
          ]
        }
      ],
      "source": [
        "!unzip /content/drive/MyDrive/SANER.zip -d /content/SANER/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFXbwjUssINH"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYwvqD8ks3_f"
      },
      "outputs": [],
      "source": [
        "PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Th_S05L_psA1",
        "outputId": "8e94095b-1ab1-4f6c-896d-67dc90625530"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SANER\n"
          ]
        }
      ],
      "source": [
        "cd /content/SANER"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "IkxnIfpPYXvy",
        "outputId": "591b7b59-0686-4a1d-ebd5-845aba8ac965"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\rbuild dataset:   0% 0/424 [00:00<?, ?it/s]\rbuild dataset:  99% 419/424 [00:00<00:00, 2791.65it/s]\rbuild dataset: 100% 424/424 [00:00<00:00, 2784.29it/s]\n",
            "\rbuild dataset:   0% 0/101 [00:00<?, ?it/s]\rbuild dataset: 100% 101/101 [00:00<00:00, 8916.35it/s]\n",
            "\rbuild dataset:   0% 0/168 [00:00<?, ?it/s]\rbuild dataset: 100% 168/168 [00:00<00:00, 12769.44it/s]\n",
            "92 out of 125 characters were found in pretrained elmo embedding.\n",
            "loading vocabulary file /content/SANER/data/bert-large-cased/vocab.txt\n",
            "Load pre-trained BERT parameters from file /content/SANER/data/bert-large-cased/pytorch_model.bin.\n",
            "Start to generate word pieces for word.\n",
            "Found(Or segment into word pieces) 2946 words out of 2953.\n",
            "Save cache to caches/sampleSet_elmo_bioes_adatrans_True_10.pkl.\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/sampler.py:64: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n",
            "  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n",
            "training epochs started 2024-07-31-16-37-11\n",
            "Evaluate data in 31.7 seconds!\n",
            "Evaluate data in 31.5 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "Evaluation on dev at Epoch 1/50. Step:212/10600: \n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "\n",
            "Evaluate data in 31.47 seconds!\n",
            "Evaluate data in 32.52 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "Evaluation on dev at Epoch 2/50. Step:424/10600: \n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "\n",
            "Evaluate data in 32.02 seconds!\n",
            "Evaluate data in 31.98 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "Evaluation on dev at Epoch 3/50. Step:636/10600: \n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "\n",
            "Evaluate data in 31.53 seconds!\n",
            "Evaluate data in 32.23 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "Evaluation on dev at Epoch 4/50. Step:848/10600: \n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "\n",
            "Evaluate data in 31.42 seconds!\n",
            "Evaluate data in 32.0 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "Evaluation on dev at Epoch 5/50. Step:1060/10600: \n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "\n",
            "Evaluate data in 31.94 seconds!\n",
            "Evaluate data in 31.33 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.071006, pre=0.375, rec=0.039216\n",
            "Evaluation on dev at Epoch 6/50. Step:1272/10600: \n",
            "SpanFPreRecMetric: f=0.032432, pre=0.5, rec=0.01676\n",
            "\n",
            "Evaluate data in 32.13 seconds!\n",
            "Evaluate data in 31.62 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.0, pre=0.0, rec=0.0\n",
            "Evaluation on dev at Epoch 7/50. Step:1484/10600: \n",
            "SpanFPreRecMetric: f=0.011111, pre=1.0, rec=0.005587\n",
            "\n",
            "Evaluate data in 32.01 seconds!\n",
            "Evaluate data in 31.26 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.012821, pre=0.333333, rec=0.006536\n",
            "Evaluation on dev at Epoch 8/50. Step:1696/10600: \n",
            "SpanFPreRecMetric: f=0.011111, pre=1.0, rec=0.005587\n",
            "\n",
            "Evaluate data in 31.67 seconds!\n",
            "Evaluate data in 31.82 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.049383, pre=0.444444, rec=0.026144\n",
            "Evaluation on dev at Epoch 9/50. Step:1908/10600: \n",
            "SpanFPreRecMetric: f=0.043478, pre=0.8, rec=0.022346\n",
            "\n",
            "Evaluate data in 32.19 seconds!\n",
            "Evaluate data in 31.13 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.04878, pre=0.363636, rec=0.026144\n",
            "Evaluation on dev at Epoch 10/50. Step:2120/10600: \n",
            "SpanFPreRecMetric: f=0.043011, pre=0.571429, rec=0.022346\n",
            "\n",
            "Evaluate data in 32.17 seconds!\n",
            "Evaluate data in 31.72 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.049689, pre=0.5, rec=0.026144\n",
            "Evaluation on dev at Epoch 11/50. Step:2332/10600: \n",
            "SpanFPreRecMetric: f=0.043011, pre=0.571429, rec=0.022346\n",
            "\n",
            "Evaluate data in 32.25 seconds!\n",
            "Evaluate data in 31.26 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.103774, pre=0.186441, rec=0.071895\n",
            "Evaluation on dev at Epoch 12/50. Step:2544/10600: \n",
            "SpanFPreRecMetric: f=0.059574, pre=0.125, rec=0.039106\n",
            "\n",
            "Evaluate data in 32.15 seconds!\n",
            "Evaluate data in 31.37 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.072727, pre=0.5, rec=0.039216\n",
            "Evaluation on dev at Epoch 13/50. Step:2756/10600: \n",
            "SpanFPreRecMetric: f=0.010989, pre=0.333333, rec=0.005587\n",
            "\n",
            "Evaluate data in 31.69 seconds!\n",
            "Evaluate data in 31.27 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.071006, pre=0.375, rec=0.039216\n",
            "Evaluation on dev at Epoch 14/50. Step:2968/10600: \n",
            "SpanFPreRecMetric: f=0.042553, pre=0.444444, rec=0.022346\n",
            "\n",
            "Evaluate data in 31.83 seconds!\n",
            "Evaluate data in 31.67 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.089385, pre=0.307692, rec=0.052288\n",
            "Evaluation on dev at Epoch 15/50. Step:3180/10600: \n",
            "SpanFPreRecMetric: f=0.061538, pre=0.375, rec=0.03352\n",
            "\n",
            "Evaluate data in 32.22 seconds!\n",
            "Evaluate data in 31.36 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.072727, pre=0.5, rec=0.039216\n",
            "Evaluation on dev at Epoch 16/50. Step:3392/10600: \n",
            "SpanFPreRecMetric: f=0.043243, pre=0.666667, rec=0.022346\n",
            "\n",
            "Evaluate data in 32.14 seconds!\n",
            "Evaluate data in 31.24 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.070588, pre=0.352941, rec=0.039216\n",
            "Evaluation on dev at Epoch 17/50. Step:3604/10600: \n",
            "SpanFPreRecMetric: f=0.042328, pre=0.4, rec=0.022346\n",
            "\n",
            "Evaluate data in 32.17 seconds!\n",
            "Evaluate data in 31.25 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.037736, pre=0.5, rec=0.019608\n",
            "Evaluation on dev at Epoch 18/50. Step:3816/10600: \n",
            "SpanFPreRecMetric: f=0.032609, pre=0.6, rec=0.01676\n",
            "\n",
            "Evaluate data in 31.93 seconds!\n",
            "Evaluate data in 31.93 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.087432, pre=0.266667, rec=0.052288\n",
            "Evaluation on dev at Epoch 19/50. Step:4028/10600: \n",
            "SpanFPreRecMetric: f=0.042105, pre=0.363636, rec=0.022346\n",
            "\n",
            "Evaluate data in 32.11 seconds!\n",
            "Evaluate data in 31.54 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.074074, pre=0.666667, rec=0.039216\n",
            "Evaluation on dev at Epoch 20/50. Step:4240/10600: \n",
            "SpanFPreRecMetric: f=0.053476, pre=0.625, rec=0.027933\n",
            "\n",
            "Evaluate data in 32.38 seconds!\n",
            "Evaluate data in 31.92 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.106383, pre=0.285714, rec=0.065359\n",
            "Evaluation on dev at Epoch 21/50. Step:4452/10600: \n",
            "SpanFPreRecMetric: f=0.079208, pre=0.347826, rec=0.044693\n",
            "\n",
            "Evaluate data in 31.6 seconds!\n",
            "Evaluate data in 31.36 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.15534, pre=0.301887, rec=0.104575\n",
            "Evaluation on dev at Epoch 22/50. Step:4664/10600: \n",
            "SpanFPreRecMetric: f=0.12093, pre=0.361111, rec=0.072626\n",
            "\n",
            "Evaluate data in 31.76 seconds!\n",
            "Evaluate data in 31.27 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.165854, pre=0.326923, rec=0.111111\n",
            "Evaluation on dev at Epoch 23/50. Step:4876/10600: \n",
            "SpanFPreRecMetric: f=0.096154, pre=0.344828, rec=0.055866\n",
            "\n",
            "Evaluate data in 31.4 seconds!\n",
            "Evaluate data in 31.47 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.158879, pre=0.278689, rec=0.111111\n",
            "Evaluation on dev at Epoch 24/50. Step:5088/10600: \n",
            "SpanFPreRecMetric: f=0.097087, pre=0.37037, rec=0.055866\n",
            "\n",
            "Evaluate data in 31.38 seconds!\n",
            "Evaluate data in 32.23 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.189055, pre=0.395833, rec=0.124183\n",
            "Evaluation on dev at Epoch 25/50. Step:5300/10600: \n",
            "SpanFPreRecMetric: f=0.130841, pre=0.4, rec=0.078212\n",
            "\n",
            "Evaluate data in 31.48 seconds!\n",
            "Evaluate data in 32.18 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.215247, pre=0.342857, rec=0.156863\n",
            "Evaluation on dev at Epoch 26/50. Step:5512/10600: \n",
            "SpanFPreRecMetric: f=0.086957, pre=0.321429, rec=0.050279\n",
            "\n",
            "Evaluate data in 31.65 seconds!\n",
            "Evaluate data in 31.6 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.208333, pre=0.287356, rec=0.163399\n",
            "Evaluation on dev at Epoch 27/50. Step:5724/10600: \n",
            "SpanFPreRecMetric: f=0.087379, pre=0.333333, rec=0.050279\n",
            "\n",
            "Evaluate data in 32.3 seconds!\n",
            "Evaluate data in 31.06 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.21875, pre=0.271845, rec=0.183007\n",
            "Evaluation on dev at Epoch 28/50. Step:5936/10600: \n",
            "SpanFPreRecMetric: f=0.114537, pre=0.270833, rec=0.072626\n",
            "\n",
            "Evaluate data in 32.37 seconds!\n",
            "Evaluate data in 31.3 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.192308, pre=0.363636, rec=0.130719\n",
            "Evaluation on dev at Epoch 29/50. Step:6148/10600: \n",
            "SpanFPreRecMetric: f=0.091371, pre=0.5, rec=0.050279\n",
            "\n",
            "Evaluate data in 31.89 seconds!\n",
            "Evaluate data in 31.56 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.242857, pre=0.267717, rec=0.222222\n",
            "Evaluation on dev at Epoch 30/50. Step:6360/10600: \n",
            "SpanFPreRecMetric: f=0.123894, pre=0.297872, rec=0.078212\n",
            "\n",
            "Evaluate data in 31.73 seconds!\n",
            "Evaluate data in 31.77 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.302632, pre=0.304636, rec=0.300654\n",
            "Evaluation on dev at Epoch 31/50. Step:6572/10600: \n",
            "SpanFPreRecMetric: f=0.165975, pre=0.322581, rec=0.111732\n",
            "\n",
            "Evaluate data in 33.24 seconds!\n",
            "Evaluate data in 30.95 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.228571, pre=0.304348, rec=0.183007\n",
            "Evaluation on dev at Epoch 32/50. Step:6784/10600: \n",
            "SpanFPreRecMetric: f=0.132701, pre=0.4375, rec=0.078212\n",
            "\n",
            "Evaluate data in 32.15 seconds!\n",
            "Evaluate data in 31.13 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.246914, pre=0.333333, rec=0.196078\n",
            "Evaluation on dev at Epoch 33/50. Step:6996/10600: \n",
            "SpanFPreRecMetric: f=0.148472, pre=0.34, rec=0.094972\n",
            "\n",
            "Evaluate data in 31.67 seconds!\n",
            "Evaluate data in 31.53 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.258993, pre=0.288, rec=0.235294\n",
            "Evaluation on dev at Epoch 34/50. Step:7208/10600: \n",
            "SpanFPreRecMetric: f=0.175299, pre=0.305556, rec=0.122905\n",
            "\n",
            "Evaluate data in 31.71 seconds!\n",
            "Evaluate data in 32.41 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.233766, pre=0.346154, rec=0.176471\n",
            "Evaluation on dev at Epoch 35/50. Step:7420/10600: \n",
            "SpanFPreRecMetric: f=0.082949, pre=0.236842, rec=0.050279\n",
            "\n",
            "Evaluate data in 32.13 seconds!\n",
            "Evaluate data in 30.88 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.271186, pre=0.385542, rec=0.20915\n",
            "Evaluation on dev at Epoch 36/50. Step:7632/10600: \n",
            "SpanFPreRecMetric: f=0.115556, pre=0.282609, rec=0.072626\n",
            "\n",
            "Evaluate data in 31.49 seconds!\n",
            "Evaluate data in 31.08 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.277966, pre=0.288732, rec=0.267974\n",
            "Evaluation on dev at Epoch 37/50. Step:7844/10600: \n",
            "SpanFPreRecMetric: f=0.196078, pre=0.328947, rec=0.139665\n",
            "\n",
            "Evaluate data in 31.87 seconds!\n",
            "Evaluate data in 31.03 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.285714, pre=0.297872, rec=0.27451\n",
            "Evaluation on dev at Epoch 38/50. Step:8056/10600: \n",
            "SpanFPreRecMetric: f=0.170543, pre=0.278481, rec=0.122905\n",
            "\n",
            "Evaluate data in 32.0 seconds!\n",
            "Evaluate data in 31.05 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.295455, pre=0.351351, rec=0.254902\n",
            "Evaluation on dev at Epoch 39/50. Step:8268/10600: \n",
            "SpanFPreRecMetric: f=0.160338, pre=0.327586, rec=0.106145\n",
            "\n",
            "Evaluate data in 31.64 seconds!\n",
            "Evaluate data in 30.91 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.336391, pre=0.316092, rec=0.359477\n",
            "Evaluation on dev at Epoch 40/50. Step:8480/10600: \n",
            "SpanFPreRecMetric: f=0.183746, pre=0.25, rec=0.145251\n",
            "\n",
            "Evaluate data in 31.07 seconds!\n",
            "Evaluate data in 30.99 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.290076, pre=0.348624, rec=0.248366\n",
            "Evaluation on dev at Epoch 41/50. Step:8692/10600: \n",
            "SpanFPreRecMetric: f=0.139738, pre=0.32, rec=0.089385\n",
            "\n",
            "Evaluate data in 32.2 seconds!\n",
            "Evaluate data in 31.37 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.29927, pre=0.338843, rec=0.267974\n",
            "Evaluation on dev at Epoch 42/50. Step:8904/10600: \n",
            "SpanFPreRecMetric: f=0.161702, pre=0.339286, rec=0.106145\n",
            "\n",
            "Evaluate data in 31.18 seconds!\n",
            "Evaluate data in 31.9 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.295533, pre=0.311594, rec=0.281046\n",
            "Evaluation on dev at Epoch 43/50. Step:9116/10600: \n",
            "SpanFPreRecMetric: f=0.178862, pre=0.328358, rec=0.122905\n",
            "\n",
            "Evaluate data in 31.64 seconds!\n",
            "Evaluate data in 31.5 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.275862, pre=0.291971, rec=0.261438\n",
            "Evaluation on dev at Epoch 44/50. Step:9328/10600: \n",
            "SpanFPreRecMetric: f=0.169355, pre=0.304348, rec=0.117318\n",
            "\n",
            "Evaluate data in 31.89 seconds!\n",
            "Evaluate data in 30.91 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.300341, pre=0.314286, rec=0.287582\n",
            "Evaluation on dev at Epoch 45/50. Step:9540/10600: \n",
            "SpanFPreRecMetric: f=0.156379, pre=0.296875, rec=0.106145\n",
            "\n",
            "Evaluate data in 33.21 seconds!\n",
            "Evaluate data in 30.89 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.304636, pre=0.308725, rec=0.300654\n",
            "Evaluation on dev at Epoch 46/50. Step:9752/10600: \n",
            "SpanFPreRecMetric: f=0.153846, pre=0.246914, rec=0.111732\n",
            "\n",
            "Evaluate data in 31.85 seconds!\n",
            "Evaluate data in 31.89 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.302405, pre=0.318841, rec=0.287582\n",
            "Evaluation on dev at Epoch 47/50. Step:9964/10600: \n",
            "SpanFPreRecMetric: f=0.179592, pre=0.333333, rec=0.122905\n",
            "\n",
            "Evaluate data in 31.72 seconds!\n",
            "Evaluate data in 30.96 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.298305, pre=0.309859, rec=0.287582\n",
            "Evaluation on dev at Epoch 48/50. Step:10176/10600: \n",
            "SpanFPreRecMetric: f=0.162602, pre=0.298507, rec=0.111732\n",
            "\n",
            "Evaluate data in 30.98 seconds!\n",
            "Evaluate data in 31.18 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.298305, pre=0.309859, rec=0.287582\n",
            "Evaluation on dev at Epoch 49/50. Step:10388/10600: \n",
            "SpanFPreRecMetric: f=0.178138, pre=0.323529, rec=0.122905\n",
            "\n",
            "Evaluate data in 31.17 seconds!\n",
            "Evaluate data in 31.37 seconds!\n",
            "EvaluateCallback evaluation on data-test:\n",
            "SpanFPreRecMetric: f=0.305556, pre=0.325926, rec=0.287582\n",
            "Evaluation on dev at Epoch 50/50. Step:10600/10600: \n",
            "SpanFPreRecMetric: f=0.174274, pre=0.33871, rec=0.117318\n",
            "\n",
            "Best test performance(may not correspond to the best dev performance):{'SpanFPreRecMetric': {'f': 0.336391, 'pre': 0.316092, 'rec': 0.359477}} achieved at Epoch:40.\n",
            "Best test performance(correspond to the best dev performance):{'SpanFPreRecMetric': {'f': 0.277966, 'pre': 0.288732, 'rec': 0.267974}} achieved at Epoch:37.\n",
            "\n",
            "In Epoch:None/Step:7844, got best dev performance:\n",
            "SpanFPreRecMetric: f=0.196078, pre=0.328947, rec=0.139665\n"
          ]
        }
      ],
      "source": [
        "!python3 /content/SANER/run.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dkiQICQft7pa"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/SANER/caches\n",
        "!rm -r /content/SANER/ckpt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "waKrfBqDq3Cj"
      },
      "source": [
        "**[NOTE4]** If we want to get the embeddings from SANER (after data augmentation), we need to:\n",
        "\n",
        "1. Obtain the labels first: we can add \"print(tgt_vocab.word2idx)\" at SANER/fastNLP/io/pipe/utils.py: line 132\n",
        "\n",
        "2. Add codes for saving embeddings of training data / test data, training data's target / test data's target. In the cell below, I marked where each piece of code needs to be inserted.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ml7vy_rcYaX7"
      },
      "outputs": [],
      "source": [
        "import datetime #No need to import datetime in trainer.py\n",
        "\n",
        "#/content/SANER/models/TENER.py: line 297\n",
        "time1 = datetime.datetime.now()\n",
        "print(\"Embed-Test: +++++++++++++++++\",time1)\n",
        "path1 = \"/content/test/test-embed-\" + str(time1) + \".pt\"\n",
        "torch.save(logits, path1)\n",
        "\n",
        "#/content/SANER/models/TENER.py: line 300\n",
        "time2 = datetime.datetime.now()\n",
        "path2 = \"/content/train/train-embed-\" + str(time2) + \".pt\"\n",
        "torch.save(logits, path2)\n",
        "\n",
        "#/content/SANER/fastNLP/core/trainer.py: line 790\n",
        "time3 = datetime.now()\n",
        "path3 = \"/content/target-train/train-label-\" + str(time3) + \".pt\"\n",
        "torch.save(batch_y['target'], path3)\n",
        "\n",
        "#/content/SANER/fastNLP/core/tester.py: line 238\n",
        "time4 = datetime.datetime.now()\n",
        "path4 = \"/content/target/test-label-\" + str(time4) + \".pt\"\n",
        "torch.save(batch_y['target'], path4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "reOoMImjuA3M"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/train/\n",
        "!mkdir /content/test/\n",
        "!mkdir /content/target/\n",
        "!mkdir /content/target-train/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xHSWRb8B26mK"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/train/\n",
        "!rm -r /content/test/\n",
        "!rm -r /content/target/\n",
        "!rm -r /content/target-train/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKCpLHWvujUc"
      },
      "source": [
        "**[NOTE5]** After this, it's some code I wrote to find the saved embeddings and their labels of last epoch, as well as the code to calculate the similarity, it may be bad, and there is some hard code, I feel so sorry for that!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CEULgDD9vinB"
      },
      "source": [
        "**[NOTE6]** First, since we have 50 epoches and we only need the embeddings after last epoch.\n",
        "\n",
        "1. For training data, we only need to choose the last one we saved, including the embeddings for training data and targets.\n",
        "\n",
        "2. For test data, I print the time for it. So I use the time to select which embedding is from the last epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0291cFKbwUQP"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/test-new/\n",
        "!mkdir /content/test-new1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J7VnyF5zhoYU"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/test-new/\n",
        "!rm -r /content/test-new1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erGt4gJTuH-z",
        "outputId": "4d4dd74c-4077-44c9-9cc0-10bdb9cfc604"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "185\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "filePath = \"/content/test/\"\n",
        "new_filePath = \"/content/test-new/\"\n",
        "os.listdir(filePath)\n",
        "filelist = os.listdir(filePath)\n",
        "count = 0\n",
        "\n",
        "for file in filelist:\n",
        "  h = int(file[22:24])  #time of hour\n",
        "  m = int(file[25:27])  #time of minute\n",
        "  s = int(file[28:30])  #time of second\n",
        "  # if the output is : Embed-Test: +++++++++++++++++ 2022-05-13 00:42:33.338923\n",
        "  # so h is 0, m is 42 and s is 33.\n",
        "  if(h==4 and ((m==29 and s>=40) or m>29)):\n",
        "    count+=1\n",
        "    shutil.copyfile(filePath + file, new_filePath + file)\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p9JpCsUfTb72",
        "outputId": "ace2b58d-8afa-4385-920d-a1e19f483f96"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "cd /content/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sV8zOdycfyVN"
      },
      "outputs": [],
      "source": [
        "!tar -zcvf test-embed-bc5cdr-siblings.tar.gz /content/test-new/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_IKsR0JMHWGK"
      },
      "outputs": [],
      "source": [
        "!tar -xzvf /content/test-embed-n2c2-5shot-lstm.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DF6yD0CaxLD9"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "filePath = \"/content/test-new/\"\n",
        "new_filePath = \"/content/test-new1/\"\n",
        "os.listdir(filePath)\n",
        "filelist = os.listdir(filePath)\n",
        "\n",
        "for file in filelist:\n",
        "  shutil.copyfile(filePath + file, new_filePath + file[25:27] + file[28:30] + file[31:-3] + \".pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LlXr4P7VxNI7",
        "outputId": "5d234716-beb3-4f34-f90d-16e6e5ea3bcb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['2940237914.pt', '2940698528.pt', '2941470341.pt', '2942126378.pt', '2943493257.pt', '2943916587.pt', '2944763516.pt', '2945557889.pt', '2947138275.pt', '2948483301.pt', '2949470736.pt', '2950000871.pt', '2951408908.pt', '2952027899.pt', '2952617306.pt', '2953472550.pt', '2954343574.pt', '2954929443.pt', '2955471138.pt', '2956177515.pt', '2956865947.pt', '2957596686.pt', '2958322094.pt', '2959183146.pt', '2959732231.pt', '3000406180.pt', '3001106408.pt', '3001889934.pt', '3002910805.pt', '3003779783.pt', '3004619385.pt', '3005174780.pt', '3005868856.pt', '3006414433.pt', '3006940442.pt', '3007575741.pt', '3008583997.pt', '3010167807.pt', '3010852699.pt', '3011748628.pt', '3012920293.pt', '3014101358.pt', '3015825771.pt', '3016576146.pt', '3017204135.pt', '3018476924.pt', '3018892735.pt', '3019505479.pt', '3020031904.pt', '3020871718.pt', '3021455880.pt', '3022149506.pt', '3023625067.pt', '3024300303.pt', '3025834696.pt', '3026435433.pt', '3027230314.pt', '3028551485.pt', '3029414814.pt', '3030252486.pt', '3030797550.pt', '3031587660.pt', '3032138217.pt', '3032697496.pt', '3033388278.pt', '3034096451.pt', '3034752974.pt', '3035748556.pt', '3037326108.pt', '3038011358.pt', '3038910106.pt', '3039613490.pt', '3040523532.pt', '3041211335.pt', '3042090226.pt', '3043037531.pt', '3043834848.pt', '3044554693.pt', '3045494218.pt', '3046134150.pt', '3046801639.pt', '3047339548.pt', '3048126097.pt', '3048784533.pt', '3049282923.pt', '3050692244.pt', '3051562070.pt', '3052232382.pt', '3052872696.pt', '3053385830.pt', '3054528602.pt', '3055617296.pt', '3056192993.pt', '3056846796.pt', '3057756101.pt', '3058422102.pt', '3058956234.pt', '3059611240.pt', '3100413483.pt', '3101550835.pt', '3102223535.pt', '3103175586.pt', '3103993026.pt', '3105258542.pt', '3106013594.pt', '3107378924.pt', '3108024467.pt', '3108881324.pt', '3109698550.pt', '3110529629.pt', '3111452286.pt', '3112084097.pt', '3113037955.pt', '3113910310.pt', '3114873451.pt', '3115784586.pt', '3116899714.pt', '3117532999.pt', '3118264134.pt', '3119104652.pt', '3120126905.pt', '3120914046.pt', '3122136588.pt', '3122831653.pt', '3123812627.pt', '3124560785.pt', '3125564826.pt', '3126268210.pt', '3127084565.pt', '3127961371.pt', '3128724111.pt', '3129579263.pt', '3130581051.pt', '3131190523.pt', '3131803330.pt', '3132670881.pt', '3133353333.pt', '3134200446.pt', '3135171737.pt', '3135717373.pt', '3136328430.pt', '3137357997.pt', '3138120955.pt', '3138846912.pt', '3139937205.pt', '3140680756.pt', '3141398186.pt', '3142884631.pt', '3143796596.pt', '3145178468.pt', '3145956588.pt', '3146564330.pt', '3147016243.pt', '3148035190.pt', '3148505251.pt', '3149227831.pt', '3150004336.pt', '3150787703.pt', '3151297080.pt', '3152264193.pt', '3152979070.pt', '3153630905.pt', '3154300882.pt', '3155187198.pt', '3155939267.pt', '3156600981.pt', '3157533516.pt', '3158214546.pt', '3159178884.pt', '3200732990.pt', '3201421565.pt', '3202138352.pt', '3203143578.pt', '3203880790.pt', '3204590581.pt', '3205272952.pt', '3205770333.pt', '3206476230.pt', '3207836970.pt', '3209391944.pt', '3210132876.pt', '3211525709.pt', '3212170678.pt', '3212816486.pt', '3213085202.pt']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "path = '/content/test-new1/'\n",
        "\n",
        "path_list = os.listdir(path)\n",
        "path_list.sort(key=lambda x:int(x.split('.')[0]))\n",
        "\n",
        "print(path_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GZfo-4MpxQus"
      },
      "outputs": [],
      "source": [
        "!mkdir /content/target-new/\n",
        "!mkdir /content/target-new1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybvFUrYyh7g6"
      },
      "outputs": [],
      "source": [
        "!rm -r /content/target-new/\n",
        "!rm -r /content/target-new1/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8UEMHNabxZQE",
        "outputId": "a8cfcd0c-4fd5-45e2-829f-81f68e81abdc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "185\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "filePath = \"/content/target/\"\n",
        "new_filePath = \"/content/target-new/\"\n",
        "os.listdir(filePath)\n",
        "filelist = os.listdir(filePath)\n",
        "count = 0\n",
        "\n",
        "for file in filelist:\n",
        "  h = int(file[22:24])\n",
        "  m = int(file[25:27])\n",
        "  s = int(file[28:30])\n",
        "  #print(file, h,m)\n",
        "  if(h==4 and ((m==29 and s>=40) or m>29)):\n",
        "    count+=1\n",
        "    shutil.copyfile(filePath + file, new_filePath + file)\n",
        "print(count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-ZVd8aNcgIbw"
      },
      "outputs": [],
      "source": [
        "!tar -zcvf test-labels-bc5cdr-siblings.tar.gz /content/target-new/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ezZ9TQuNHoSb"
      },
      "outputs": [],
      "source": [
        "!tar -xzvf /content/test-labels-i2b2-1shot-top2_dont_need.tar.gz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cNvLpevNxbgb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "filePath = \"/content/target-new/\"\n",
        "new_filePath = \"/content/target-new1/\"\n",
        "os.listdir(filePath)\n",
        "filelist = os.listdir(filePath)\n",
        "\n",
        "for file in filelist:\n",
        "  shutil.copyfile(filePath + file, new_filePath + file[25:27] + file[28:30] + file[31:-3] + \".pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hlk9Y52xxdYc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "path1 = '/content/target-new1/'\n",
        "\n",
        "path_list_labels = os.listdir(path1)\n",
        "path_list_labels.sort(key=lambda x:int(x.split('.')[0]))\n",
        "\n",
        "print(path_list_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h1MYk_TFiRxS"
      },
      "outputs": [],
      "source": [
        "path_list = path_list[1:]\n",
        "path_list_labels = path_list_labels[1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KLY5LV-xjx5S"
      },
      "outputs": [],
      "source": [
        "path_list_labels = path_list_labels[2:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUDVrKM4iU8r",
        "outputId": "4686b967-679f-4b1a-b26b-2d741cb20037"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "184\n",
            "184\n"
          ]
        }
      ],
      "source": [
        "print(len(path_list))\n",
        "print(len(path_list_labels))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-MyHruhxlGH"
      },
      "source": [
        "**[NOTE7]** Then we can try NNShot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FVfumvn-x1wK"
      },
      "outputs": [],
      "source": [
        "!pip install seqeval"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b71cJZMsyGEv"
      },
      "source": [
        "**[NOTE7]** We need to get the embeddings of training data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F2OqsVQqx_oZ",
        "outputId": "c40ce892-5f78-478b-c42b-3d84971e47de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([24, 44, 9])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "support_encodings = torch.load('/content/train/train-embed-2023-03-14 04:27:15.685682.pt') #the last one in /content/train\n",
        "print(support_encodings.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w-fmOtquP2D4",
        "outputId": "a6bc751c-172e-4a8a-ff3f-917af904010b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([24, 44])\n",
            "tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        ...,\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0],\n",
            "        [0, 0, 0,  ..., 0, 0, 0]])\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "support_labels = torch.load('/content/target-train/train-label-2023-03-14 04:27:15.101574.pt')\n",
        "print(support_labels.shape)\n",
        "print(support_labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jiO8QulgypVn"
      },
      "source": [
        "**[NOTE8]** Then, We need to get the embeddings of training data's labels, and transfer the labels from BIOES to IO. Here I used some hard code :( , I weill use N2C2 data as an example.\n",
        "\n",
        "  1. We need: \"target_labels\", and \"reversed_label_map\". Then we can get \"label_map\".\n",
        "\n",
        "  2. Then we need to transfer the labels from BIOES to IO, but actually, only need to change the number. That means we need to change the number (which represents label) from \"reversed_label_map\" to \"reversed_IO_map\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jYkfTwPdqqd"
      },
      "outputs": [],
      "source": [
        "#bc5cdr\n",
        "target_labels = ['O', 'S-Chemical', 'S-Disease', 'B-Disease', 'E-Disease', 'I-Disease', 'B-Chemical', 'E-Chemical', 'I-Chemical']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cGB82nlJWR82"
      },
      "outputs": [],
      "source": [
        "target_labels = ['O', 'S-DATE', 'B-DOCTOR', 'E-DOCTOR', 'S-DOCTOR', 'S-AGE',\n",
        " 'S-PATIENT', 'S-HOSPITAL', 'B-HOSPITAL', 'E-HOSPITAL', 'B-PATIENT',\n",
        " 'E-PATIENT', 'S-MEDICALRECORD', 'B-DATE', 'E-DATE', 'I-HOSPITAL',\n",
        " 'I-DOCTOR', 'I-DATE', 'S-CITY', 'S-STATE', 'I-STREET',\n",
        " 'S-ZIP', 'B-STREET', 'E-STREET', 'S-PHONE', 'S-COUNTRY',\n",
        " 'S-IDNUM', 'S-USERNAME', 'B-PROFESSION', 'E-PROFESSION', 'S-PROFESSION',\n",
        " 'B-CITY', 'E-CITY', 'I-PROFESSION', 'B-PHONE', 'E-PHONE',\n",
        " 'B-ORGANIZATION', 'E-ORGANIZATION', 'S-ORGANIZATION', 'I-PATIENT', 'I-ORGANIZATION',\n",
        " 'B-STATE', 'E-STATE', 'B-COUNTRY', 'E-COUNTRY', 'B-MEDICALRECORD',\n",
        " 'E-MEDICALRECORD', 'B-LOCATIONOTHER', 'E-LOCATIONOTHER', 'I-MEDICALRECORD', 'I-COUNTRY',\n",
        " 'I-CITY', 'S-LOCATIONOTHER', 'I-URL', 'S-EMAIL', 'S-BIOID',\n",
        " 'B-HEALTHPLAN', 'E-HEALTHPLAN', 'B-URL', 'E-URL', 'S-FAX',\n",
        " 'B-FAX', 'E-FAX', 'B-IDNUM', 'E-IDNUM', 'B-AGE',\n",
        " 'E-AGE', 'B-DEVICE', 'E-DEVICE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ugGZti_ZQJJ0"
      },
      "outputs": [],
      "source": [
        "target_labels = ['O', 'S-Drug', 'S-Form', 'S-Route', 'B-Strength', 'E-Strength', 'S-Frequency', 'S-Reason', 'B-Dosage', 'E-Dosage', 'S-Dosage', 'I-Frequency', 'S-Strength', 'B-Frequency', 'E-Frequency', 'B-Reason', 'E-Reason', 'B-Drug', 'E-Drug', 'I-Reason', 'S-ADE', 'B-Duration', 'E-Duration', 'B-Form', 'E-Form', 'I-Duration', 'B-ADE', 'E-ADE', 'B-Route', 'E-Route', 'I-Strength', 'I-ADE', 'I-Drug', 'I-Form', 'I-Dosage', 'S-Duration', 'I-Route']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YDv6908TJ_K7"
      },
      "outputs": [],
      "source": [
        "target_labels = ['O', 'S-DATE', 'B-DOCTOR', 'E-DOCTOR', 'S-DOCTOR', 'S-AGE', 'S-PATIENT', 'S-HOSPITAL', 'B-PATIENT', 'E-PATIENT', 'B-HOSPITAL', 'E-HOSPITAL', 'S-MEDICALRECORD', 'B-DATE', 'E-DATE', 'I-HOSPITAL', 'I-DOCTOR', 'I-DATE', 'S-CITY', 'S-STATE', 'I-STREET', 'S-ZIP', 'B-STREET', 'E-STREET', 'S-PHONE', 'S-COUNTRY', 'S-IDNUM', 'S-USERNAME', 'B-PROFESSION', 'E-PROFESSION', 'S-PROFESSION', 'B-CITY', 'E-CITY', 'B-ORGANIZATION', 'E-ORGANIZATION', 'I-PROFESSION', 'B-PHONE', 'E-PHONE', 'S-ORGANIZATION', 'I-PATIENT', 'I-ORGANIZATION', 'B-STATE', 'E-STATE', 'B-LOCATIONOTHER', 'E-LOCATIONOTHER', 'B-COUNTRY', 'E-COUNTRY', 'B-MEDICALRECORD', 'E-MEDICALRECORD', 'I-MEDICALRECORD', 'S-DEVICE', 'S-FAX', 'I-LOCATIONOTHER', 'S-EMAIL', 'I-COUNTRY', 'I-CITY', 'S-LOCATIONOTHER', 'B-HEALTHPLAN', 'E-HEALTHPLAN', 'B-URL', 'I-URL', 'E-URL', 'S-BIOID', 'B-FAX', 'E-FAX', 'B-IDNUM', 'E-IDNUM', 'B-AGE', 'E-AGE', 'B-DEVICE', 'E-DEVICE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKzYn-ymJpvE"
      },
      "outputs": [],
      "source": [
        "target_labels = ['O', 'I-SYMPTOM', 'B-SYMPTOM', 'E-SYMPTOM', 'I-MEASUREMENT', 'S-SYMPTOM', 'B-MEASUREMENT', 'E-MEASUREMENT', 'S-EVENT', 'S-DRUG', 'B-LOCATION', 'E-LOCATION', 'B-EVENT', 'E-EVENT', 'I-EVENT', 'B-AMOUNT', 'E-AMOUNT', 'I-TIME', 'I-LOCATION', 'B-TIME', 'E-TIME', 'S-LOCATION', 'I-AMOUNT', 'S-AGE', 'S-AMOUNT', 'S-GENDER', 'S-MEASUREMENT', 'B-DRUG', 'E-DRUG', 'S-ORGANIZATION', 'S-TIME', 'S-FREQUENCY', 'B-ORGANIZATION', 'E-ORGANIZATION', 'B-FREQUENCY', 'E-FREQUENCY', 'I-ORGANIZATION', 'B-AGE', 'E-AGE', 'I-DRUG', 'S-DATE', 'I-FREQUENCY']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6XCvbapry1CC",
        "outputId": "d2464e01-6dff-4b49-ac7c-bd9f47e7fded"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'O', 1: 'S-Chemical', 2: 'S-Disease', 3: 'B-Disease', 4: 'E-Disease', 5: 'I-Disease', 6: 'B-Chemical', 7: 'E-Chemical', 8: 'I-Chemical'}\n"
          ]
        }
      ],
      "source": [
        "label_map = {i: label for i, label in enumerate(target_labels)}\n",
        "print(label_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mc3EE5giN3mo"
      },
      "outputs": [],
      "source": [
        "target_labels = ['O', 'S-Drug', 'S-Form', 'S-Route', 'B-Strength', 'E-Strength', 'S-Frequency', 'S-Reason', 'B-Dosage', 'E-Dosage', 'S-Dosage', 'I-Frequency', 'S-Strength', 'B-Frequency', 'E-Frequency', 'B-Reason', 'E-Reason', 'B-Drug', 'E-Drug', 'I-Reason', 'S-ADE', 'B-Duration', 'E-Duration', 'B-Form', 'E-Form', 'I-Duration', 'B-ADE', 'E-ADE', 'B-Route', 'E-Route', 'I-Strength', 'I-ADE', 'I-Drug', 'I-Form', 'I-Dosage', 'S-Duration', 'I-Route']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO6bTkZeOXJx"
      },
      "outputs": [],
      "source": [
        "reversed_label_map = {'O': 0, 'S-Drug': 1, 'S-Form': 2, 'S-Route': 3, 'B-Strength': 4, 'E-Strength': 5, 'S-Frequency': 6, 'S-Reason': 7, 'B-Dosage': 8, 'E-Dosage': 9, 'S-Dosage': 10, 'I-Frequency': 11, 'S-Strength': 12, 'B-Frequency': 13, 'E-Frequency': 14, 'B-Reason': 15, 'E-Reason': 16, 'B-Drug': 17, 'E-Drug': 18, 'I-Reason': 19, 'S-ADE': 20, 'B-Duration': 21, 'E-Duration': 22, 'B-Form': 23, 'E-Form': 24, 'I-Duration': 25, 'B-ADE': 26, 'E-ADE': 27, 'B-Route': 28, 'E-Route': 29, 'I-Strength': 30, 'I-ADE': 31, 'I-Drug': 32, 'I-Form': 33, 'I-Dosage': 34, 'S-Duration': 35, 'I-Route': 36}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JskoD2yveA5K",
        "outputId": "68347f0c-a19c-4e91-e4ca-ad742eb7bce8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([1056])\n",
            "tensor([0, 0, 0,  ..., 0, 0, 0])\n"
          ]
        }
      ],
      "source": [
        "#bc5cdr\n",
        "def bioes2io(target):\n",
        "        x_num,y_num = target.shape\n",
        "        for i in range(x_num):\n",
        "              for j in range(y_num):\n",
        "                if(target[i][j]==1 or target[i][j]==6 or target[i][j]==7 or target[i][j]==8):\n",
        "                  target[i][j] = 1\n",
        "                if(target[i][j]==2 or target[i][j]==3 or target[i][j]==4 or target[i][j]==5):\n",
        "                  target[i][j] = 2\n",
        "        return target\n",
        "\n",
        "#TANER 361\n",
        "#support_encodings = support_labels\n",
        "#print(x_num,y_num)\n",
        "support_IO_labels = bioes2io(support_labels)\n",
        "#print(support_IO_labels)\n",
        "n,p = support_labels.shape\n",
        "support_IO_labels = support_IO_labels.reshape(n*p)\n",
        "print(support_IO_labels.shape)\n",
        "print(support_IO_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YwGN-p4AR6tH"
      },
      "outputs": [],
      "source": [
        "#TENER line 271\n",
        "def bioes2io(target):\n",
        "        x_num,y_num = target.shape\n",
        "        for i in range(x_num):\n",
        "              for j in range(y_num):\n",
        "                if(target[i][j]==1 or target[i][j]==2 or target[i][j]==3 or target[i][j]==5):\n",
        "                  target[i][j] = 1\n",
        "                if(target[i][j]==4 or target[i][j]==6 or target[i][j]==7 or target[i][j]==26):\n",
        "                  target[i][j] = 2\n",
        "                if(target[i][j]==8 or target[i][j]==12 or target[i][j]==13 or target[i][j]==14):\n",
        "                  target[i][j] = 3\n",
        "                if(target[i][j]==9 or target[i][j]==27 or target[i][j]==28 or target[i][j]==39):\n",
        "                  target[i][j] = 4\n",
        "                if(target[i][j]==10 or target[i][j]==11 or target[i][j]==18 or target[i][j]==21):\n",
        "                  target[i][j] = 5\n",
        "                if(target[i][j]==15 or target[i][j]==16 or target[i][j]==22 or target[i][j]==24):\n",
        "                  target[i][j] = 6\n",
        "                if(target[i][j]==23 or target[i][j]==37 or target[i][j]==38):\n",
        "                  target[i][j] = 8\n",
        "                if(target[i][j]==19 or target[i][j]==17 or target[i][j]==20 or target[i][j]==30):\n",
        "                  target[i][j] = 7\n",
        "                if(target[i][j]==25):\n",
        "                  target[i][j] = 9\n",
        "                if(target[i][j]==29 or target[i][j]==32 or target[i][j]==33 or target[i][j]==36):\n",
        "                  target[i][j] = 10\n",
        "                if(target[i][j]==31 or target[i][j]==34 or target[i][j]==35 or target[i][j]==41):\n",
        "                  target[i][j] = 11\n",
        "                if(target[i][j]==40):\n",
        "                  target[i][j] = 12\n",
        "        return target\n",
        "\n",
        "#TANER 361\n",
        "#support_encodings = support_labels\n",
        "#print(x_num,y_num)\n",
        "support_IO_labels = bioes2io(support_labels)\n",
        "#print(support_IO_labels)\n",
        "n,p = support_labels.shape\n",
        "support_IO_labels = support_IO_labels.reshape(n*p)\n",
        "print(support_IO_labels.shape)\n",
        "print(support_IO_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ry-PbHLhQXeM"
      },
      "outputs": [],
      "source": [
        "#TENER line 271\n",
        "def bioes2io(target):\n",
        "        x_num,y_num = target.shape\n",
        "        for i in range(x_num):\n",
        "              for j in range(y_num):\n",
        "                if(target[i][j]==1 or target[i][j]==17 or target[i][j]==18 or target[i][j]==32):\n",
        "                  target[i][j] = 1\n",
        "                if(target[i][j]==2 or target[i][j]==23 or target[i][j]==24 or target[i][j]==33):\n",
        "                  target[i][j] = 2\n",
        "                if(target[i][j]==3 or target[i][j]==28 or target[i][j]==29 or target[i][j]==36):\n",
        "                  target[i][j] = 3\n",
        "                if(target[i][j]==4 or target[i][j]==5 or target[i][j]==12 or target[i][j]==30):\n",
        "                  target[i][j] = 4\n",
        "                if(target[i][j]==6 or target[i][j]==11 or target[i][j]==13 or target[i][j]==14):\n",
        "                  target[i][j] = 5\n",
        "                if(target[i][j]==7 or target[i][j]==15 or target[i][j]==16 or target[i][j]==19):\n",
        "                  target[i][j] = 6\n",
        "                if(target[i][j]==8 or target[i][j]==9 or target[i][j]==10 or target[i][j]==34):\n",
        "                  target[i][j] = 7\n",
        "                if(target[i][j]==20 or target[i][j]==26 or target[i][j]==27 or target[i][j]==31):\n",
        "                  target[i][j] = 8\n",
        "                if(target[i][j]==21 or target[i][j]==22 or target[i][j]==25 or target[i][j]==35):\n",
        "                  target[i][j] = 9\n",
        "        return target\n",
        "\n",
        "#TANER 361\n",
        "#support_encodings = support_labels\n",
        "#print(x_num,y_num)\n",
        "support_IO_labels = bioes2io(support_labels)\n",
        "#print(support_IO_labels)\n",
        "n,p = support_labels.shape\n",
        "support_IO_labels = support_IO_labels.reshape(n*p)\n",
        "print(support_IO_labels.shape)\n",
        "print(support_IO_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J0sJRpEaWakP"
      },
      "outputs": [],
      "source": [
        "#TENER line 271\n",
        "def bioes2io(target):\n",
        "        x_num,y_num = target.shape\n",
        "        for i in range(x_num):\n",
        "              for j in range(y_num):\n",
        "                if(target[i][j]==1 or target[i][j]==14 or target[i][j]==13 or target[i][j]==17):\n",
        "                  target[i][j] = 14\n",
        "                if(target[i][j]==2 or target[i][j]==3 or target[i][j]==4 or target[i][j]==16):\n",
        "                  target[i][j] = 2\n",
        "                if(target[i][j]==5 or target[i][j]==66 or target[i][j]==65):\n",
        "                  target[i][j] = 13\n",
        "                if(target[i][j]==6 or target[i][j]==10 or target[i][j]==11 or target[i][j]==39):\n",
        "                  target[i][j] = 1\n",
        "                if(target[i][j]==7 or target[i][j]==8 or target[i][j]==9 or target[i][j]==15):\n",
        "                  target[i][j] = 5\n",
        "                if(target[i][j]==12 or target[i][j]==45 or target[i][j]==46 or target[i][j]==49):\n",
        "                  target[i][j] = 20\n",
        "                if(target[i][j]==18 or target[i][j]==31 or target[i][j]==32 or target[i][j]==51):\n",
        "                  target[i][j] = 8\n",
        "                if(target[i][j]==19 or target[i][j]==41 or target[i][j]==42):\n",
        "                  target[i][j] = 9\n",
        "                if(target[i][j]==25 or target[i][j]==43 or target[i][j]==44 or target[i][j]==50):\n",
        "                  target[i][j] = 10\n",
        "                if(target[i][j]==21):\n",
        "                  target[i][j] = 11\n",
        "                if(target[i][j]==22 or target[i][j]==23 or target[i][j]==20):\n",
        "                  target[i][j] = 7\n",
        "                if(target[i][j]==24 or target[i][j]==35 or target[i][j]==34):\n",
        "                  target[i][j] = 15\n",
        "                if(target[i][j]==27):\n",
        "                  target[i][j] = 3\n",
        "                if(target[i][j]==26 or target[i][j]==64 or target[i][j]==63):\n",
        "                  target[i][j] = 21\n",
        "                if(target[i][j]==28 or target[i][j]==29 or target[i][j]==30 or target[i][j]==33):\n",
        "                  target[i][j] = 4\n",
        "                if(target[i][j]==37 or target[i][j]==36 or target[i][j]==38 or target[i][j]==40):\n",
        "                  target[i][j] = 6\n",
        "                if(target[i][j]==48 or target[i][j]==47 or target[i][j]==52):\n",
        "                  target[i][j] = 12\n",
        "                if(target[i][j]==53 or target[i][j]==59 or target[i][j]==58):\n",
        "                  target[i][j] = 18\n",
        "                if(target[i][j]==54):\n",
        "                  target[i][j] = 17\n",
        "                if(target[i][j]==55):\n",
        "                  target[i][j] = 23\n",
        "                if(target[i][j]==56 or target[i][j]==57):\n",
        "                  target[i][j] = 19\n",
        "                if(target[i][j]==62 or target[i][j]==60 or target[i][j]==61):\n",
        "                  target[i][j] = 16\n",
        "                if(target[i][j]==67 or target[i][j]==68):\n",
        "                  target[i][j] = 22\n",
        "        return target\n",
        "\n",
        "#TANER 361\n",
        "#support_encodings = support_labels\n",
        "#print(x_num,y_num)\n",
        "support_IO_labels = bioes2io(support_labels)\n",
        "#print(support_IO_labels)\n",
        "n,p = support_labels.shape\n",
        "support_IO_labels = support_IO_labels.reshape(n*p)\n",
        "print(support_IO_labels.shape)\n",
        "print(support_IO_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJM-r4POS7Uq"
      },
      "outputs": [],
      "source": [
        "#TENER line 271\n",
        "def bioes2io(target):\n",
        "        x_num,y_num = target.shape\n",
        "        for i in range(x_num):\n",
        "              for j in range(y_num):\n",
        "                if(target[i][j]==1 or target[i][j]==2 or target[i][j]==3 or target[i][j]==5):\n",
        "                  target[i][j] = 1\n",
        "                if(target[i][j]==4 or target[i][j]==6 or target[i][j]==7 or target[i][j]==26):\n",
        "                  target[i][j] = 2\n",
        "                if(target[i][j]==8 or target[i][j]==12 or target[i][j]==13 or target[i][j]==14):\n",
        "                  target[i][j] = 3\n",
        "                if(target[i][j]==9 or target[i][j]==27 or target[i][j]==28 or target[i][j]==39):\n",
        "                  target[i][j] = 4\n",
        "                if(target[i][j]==10 or target[i][j]==11 or target[i][j]==18 or target[i][j]==21):\n",
        "                  target[i][j] = 5\n",
        "                if(target[i][j]==15 or target[i][j]==16 or target[i][j]==22 or target[i][j]==24):\n",
        "                  target[i][j] = 6\n",
        "                if(target[i][j]==23 or target[i][j]==37 or target[i][j]==38):\n",
        "                  target[i][j] = 8\n",
        "                if(target[i][j]==19 or target[i][j]==17 or target[i][j]==20 or target[i][j]==30):\n",
        "                  target[i][j] = 7\n",
        "                if(target[i][j]==25):\n",
        "                  target[i][j] = 9\n",
        "                if(target[i][j]==29 or target[i][j]==32 or target[i][j]==33 or target[i][j]==36):\n",
        "                  target[i][j] = 10\n",
        "                if(target[i][j]==31 or target[i][j]==34 or target[i][j]==35 or target[i][j]==41):\n",
        "                  target[i][j] = 11\n",
        "                if(target[i][j]==40):\n",
        "                  target[i][j] = 12\n",
        "        return target\n",
        "\n",
        "#TANER 361\n",
        "#support_encodings = support_labels\n",
        "#print(x_num,y_num)\n",
        "support_IO_labels = bioes2io(support_labels)\n",
        "#print(support_IO_labels)\n",
        "n,p = support_labels.shape\n",
        "support_IO_labels = support_IO_labels.reshape(n*p)\n",
        "print(support_IO_labels.shape)\n",
        "print(support_IO_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0AuPZG_yOktD"
      },
      "outputs": [],
      "source": [
        "#TENER line 271\n",
        "def bioes2io(target):\n",
        "        x_num,y_num = target.shape\n",
        "        for i in range(x_num):\n",
        "              for j in range(y_num):\n",
        "                if(target[i][j]==1 or target[i][j]==17 or target[i][j]==18 or target[i][j]==32):\n",
        "                  target[i][j] = 1\n",
        "                if(target[i][j]==2 or target[i][j]==23 or target[i][j]==24 or target[i][j]==33):\n",
        "                  target[i][j] = 2\n",
        "                if(target[i][j]==3 or target[i][j]==28 or target[i][j]==29 or target[i][j]==36):\n",
        "                  target[i][j] = 3\n",
        "                if(target[i][j]==4 or target[i][j]==5 or target[i][j]==12 or target[i][j]==30):\n",
        "                  target[i][j] = 4\n",
        "                if(target[i][j]==6 or target[i][j]==11 or target[i][j]==13 or target[i][j]==14):\n",
        "                  target[i][j] = 5\n",
        "                if(target[i][j]==7 or target[i][j]==15 or target[i][j]==16 or target[i][j]==19):\n",
        "                  target[i][j] = 6\n",
        "                if(target[i][j]==8 or target[i][j]==9 or target[i][j]==10 or target[i][j]==34):\n",
        "                  target[i][j] = 7\n",
        "                if(target[i][j]==20 or target[i][j]==26 or target[i][j]==27 or target[i][j]==31):\n",
        "                  target[i][j] = 8\n",
        "                if(target[i][j]==21 or target[i][j]==22 or target[i][j]==25 or target[i][j]==35):\n",
        "                  target[i][j] = 9\n",
        "        return target\n",
        "\n",
        "#TANER 361\n",
        "#support_encodings = support_labels\n",
        "#print(x_num,y_num)\n",
        "support_IO_labels = bioes2io(support_labels)\n",
        "#print(support_IO_labels)\n",
        "n,p = support_labels.shape\n",
        "support_IO_labels = support_IO_labels.reshape(n*p)\n",
        "print(support_IO_labels.shape)\n",
        "print(support_IO_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5JZj7rtPWeHf"
      },
      "outputs": [],
      "source": [
        "reversed_IO_map = {'O': 0, 'I-PATIENT': 1, 'I-DOCTOR': 2, 'I-USERNAME': 3, 'I-PROFESSION': 4, 'I-HOSPITAL': 5,\n",
        "'I-ORGANIZATION': 6, 'I-STREET': 7, 'I-CITY': 8, 'I-STATE': 9, 'I-COUNTRY': 10,\n",
        "'I-ZIP': 11, 'I-LOCATIONOTHER': 12, 'I-AGE': 13, 'I-DATE': 14, 'I-PHONE': 15,\n",
        "'I-FAX': 16, 'I-EMAIL': 17, 'I-URL': 18, 'I-HEALTHPLAN': 19,\n",
        "'I-MEDICALRECORD': 20, 'I-IDNUM': 21, 'I-DEVICE': 22, 'I-BIOID': 23}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_60t9f5nWrSr"
      },
      "outputs": [],
      "source": [
        "target_IO_labels = ['O', 'I-PATIENT', 'I-DOCTOR', 'I-USERNAME', 'I-PROFESSION', 'I-HOSPITAL',\n",
        "'I-ORGANIZATION', 'I-STREET', 'I-CITY', 'I-STATE', 'I-COUNTRY',\n",
        "'I-ZIP', 'I-LOCATIONOTHER', 'I-AGE', 'I-DATE', 'I-PHONE',\n",
        "'I-FAX', 'I-EMAIL', 'I-URL', 'I-HEALTHPLAN',\n",
        "'I-MEDICALRECORD', 'I-IDNUM', 'I-DEVICE', 'I-BIOID']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2sDUbNYQ9K_"
      },
      "outputs": [],
      "source": [
        "reversed_IO_map = {'O': 0, 'I-Drug': 1, 'I-Form': 2, 'I-Route': 3, 'I-Strength': 4, 'I-Frequency': 5,\n",
        " 'I-Reason': 6, 'I-Dosage': 7, 'I-ADE': 8, 'I-Duration': 9}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vKOmmeCDQ-2H"
      },
      "outputs": [],
      "source": [
        "target_IO_labels = {'O', 'I-Drug', 'I-Form', 'I-Route', 'I-Strength', 'I-Frequency',\n",
        " 'I-Reason', 'I-Dosage', 'I-ADE', 'I-Duration'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYso85U-KQIM"
      },
      "outputs": [],
      "source": [
        "reversed_label_map = {'O': 0, 'S-DATE': 1, 'B-DOCTOR': 2, 'E-DOCTOR': 3, 'S-DOCTOR': 4, 'S-AGE': 5, 'S-PATIENT': 6, 'S-HOSPITAL': 7, 'B-PATIENT': 8, 'E-PATIENT': 9, 'B-HOSPITAL': 10, 'E-HOSPITAL': 11, 'S-MEDICALRECORD': 12, 'B-DATE': 13, 'E-DATE': 14, 'I-HOSPITAL': 15, 'I-DOCTOR': 16, 'I-DATE': 17, 'S-CITY': 18, 'S-STATE': 19, 'I-STREET': 20, 'S-ZIP': 21, 'B-STREET': 22, 'E-STREET': 23, 'S-PHONE': 24, 'S-COUNTRY': 25, 'S-IDNUM': 26, 'S-USERNAME': 27, 'B-PROFESSION': 28, 'E-PROFESSION': 29, 'S-PROFESSION': 30, 'B-CITY': 31, 'E-CITY': 32, 'B-ORGANIZATION': 33, 'E-ORGANIZATION': 34, 'I-PROFESSION': 35, 'B-PHONE': 36, 'E-PHONE': 37, 'S-ORGANIZATION': 38, 'I-PATIENT': 39, 'I-ORGANIZATION': 40, 'B-STATE': 41, 'E-STATE': 42, 'B-LOCATIONOTHER': 43, 'E-LOCATIONOTHER': 44, 'B-COUNTRY': 45, 'E-COUNTRY': 46, 'B-MEDICALRECORD': 47, 'E-MEDICALRECORD': 48, 'I-MEDICALRECORD': 49, 'S-DEVICE': 50, 'S-FAX': 51, 'I-LOCATIONOTHER': 52, 'S-EMAIL': 53, 'I-COUNTRY': 54, 'I-CITY': 55, 'S-LOCATIONOTHER': 56, 'B-HEALTHPLAN': 57, 'E-HEALTHPLAN': 58, 'B-URL': 59, 'I-URL': 60, 'E-URL': 61, 'S-BIOID': 62, 'B-FAX': 63, 'E-FAX': 64, 'B-IDNUM': 65, 'E-IDNUM': 66, 'B-AGE': 67, 'E-AGE': 68, 'B-DEVICE': 69, 'E-DEVICE': 70}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bV-N6u3cxLgu"
      },
      "outputs": [],
      "source": [
        "reversed_IO_map = {'O': 0, 'I-SYMPTOM': 1, 'I-MEASUREMENT': 2, 'I-EVENT': 3, 'I-DRUG': 4, 'I-LOCATION': 5,\n",
        " 'I-AMOUNT': 6, 'I-TIME': 7, 'I-AGE': 8, 'I-GENDER': 9, 'I-ORGANIZATION': 10,\n",
        " 'I-FREQUENCY': 11, 'I-DATE': 12}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwjEFln1xOfR"
      },
      "outputs": [],
      "source": [
        "target_IO_labels = ['O', 'I-SYMPTOM', 'I-MEASUREMENT', 'I-EVENT', 'I-DRUG', 'I-LOCATION',\n",
        " 'I-AMOUNT', 'I-TIME', 'I-AGE', 'I-GENDER', 'I-ORGANIZATION',\n",
        " 'I-FREQUENCY', 'I-DATE']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m3oOtOQZOunm"
      },
      "outputs": [],
      "source": [
        "reversed_IO_map = {'O': 0, 'I-Drug': 1, 'I-Form': 2, 'I-Route': 3, 'I-Strength': 4, 'I-Frequency': 5,\n",
        " 'I-Reason': 6, 'I-Dosage': 7, 'I-ADE': 8, 'I-Duration': 9}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xNkwF6LuOvQg"
      },
      "outputs": [],
      "source": [
        "target_IO_labels = {'O', 'I-Drug', 'I-Form', 'I-Route', 'I-Strength', 'I-Frequency',\n",
        " 'I-Reason', 'I-Dosage', 'I-ADE', 'I-Duration'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVAGOCL_ephQ"
      },
      "outputs": [],
      "source": [
        "#bc5cdr\n",
        "target_IO_labels = {'O', 'I-Chemical', 'I-Disease'}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HFyGoGW2z8k-",
        "outputId": "32d0269f-4c1a-45c7-b679-b8cfc06937d3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{0: 'I-Disease', 1: 'I-Chemical', 2: 'O'}\n",
            "{'I-Disease': 0, 'I-Chemical': 1, 'O': 2}\n"
          ]
        }
      ],
      "source": [
        "IO_label_map = {i: label for i, label in enumerate(target_IO_labels)}\n",
        "print(IO_label_map)\n",
        "reversed_IO_map = {label: i for i, label in enumerate(target_IO_labels)}\n",
        "print(reversed_IO_map)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BP50K2d5009a"
      },
      "source": [
        "**[NOTE9]** Now we can calculate the similarity!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uwBuhVbjNXg8"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import torch\n",
        "\n",
        "import torch.nn.functional as F\n",
        "import numpy as np\n",
        "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from tqdm import tqdm\n",
        "from scipy import spatial\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "def nn_decode(reps, support_reps, support_tags):\n",
        "    \"\"\"\n",
        "    NNShot: neariest neighbor decoder for few-shot NER\n",
        "    \"\"\"\n",
        "    batch_size, sent_len, ndim = reps.shape\n",
        "    scores = _euclidean_metric(reps.view(-1, ndim), support_reps.view(-1, ndim), True)\n",
        "    emissions = get_nn_emissions(scores, support_tags)\n",
        "    tags = torch.argmax(emissions, 1)\n",
        "    return tags.view(batch_size, sent_len), emissions.view(batch_size, sent_len, -1)\n",
        "\n",
        "\n",
        "def get_nn_emissions(scores, tags):\n",
        "    \"\"\"\n",
        "    Obtain emission scores from NNShot\n",
        "    \"\"\"\n",
        "    n, m = scores.shape\n",
        "    n_tags = torch.max(tags) + 1\n",
        "    emissions = -100000. * torch.ones(n, n_tags).to(scores.device)\n",
        "    for t in range(n_tags):\n",
        "        mask = (tags == t).float().view(1, -1).to(device)\n",
        "        masked = scores * mask\n",
        "        masked = torch.where(masked < 0, masked, torch.tensor(-100000.).to(scores.device))\n",
        "        emissions[:, t] = torch.max(masked, dim=1)[0]\n",
        "    return emissions\n",
        "\n",
        "#def normalize(x, axis=-1):\n",
        "    #x = 1. * x / (torch.norm(x, 2, axis, keepdim=True).expand_as(x) + 1e-12)\n",
        "    #return x\n",
        "\n",
        "def _euclidean_metric(a, b, normalize=False):\n",
        "    if normalize:\n",
        "        a = F.normalize(a)\n",
        "        b = F.normalize(b)\n",
        "    n = a.shape[0]\n",
        "    m = b.shape[0]\n",
        "    a = a.unsqueeze(1).expand(n, m, -1)\n",
        "    b = b.unsqueeze(0).expand(n, m, -1)\n",
        "    #print(a.shape)\n",
        "    #print(b.shape)\n",
        "\n",
        "    #logits = -((a - b) ** 2).sum(dim=2)\n",
        "    #logits = -torch.norm(a-b, p=1,dim=2)   #manhatan distance\n",
        "    logits = -torch.norm(a-b, p=3,dim=2)\n",
        "\n",
        "    #a =a.mean(dim=0, keepdims=True)\n",
        "    #b =b.mean(dim=0, keepdims=True)\n",
        "    #logits = torch.cosine_similarity(a.unsqueeze(1), b.unsqueeze(0), dim=-1)\n",
        "    #pdist = torch.nn.PairwiseDistance(p=2)\n",
        "    #logits = pdist(a,b)\n",
        "\n",
        "    #cos = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)\n",
        "    #logits = cos(a,b)\n",
        "\n",
        "    #a,b=normalize(a),normalize(b)\n",
        "    #logits = cos=1-torch.mm(a,b.permute(1,0))\n",
        "    #print(logits.shape)\n",
        "\n",
        "    #logits = -(1-torch.cosine_similarity(a, b, dim=-1))   #cosine similarity\n",
        "    #print(logits)\n",
        "\n",
        "    #logits = torch.cdist(a,b,p=2)\n",
        "    #print(logits.shape)\n",
        "\n",
        "    #logits = pairwise_manhattan_distance(a, b)\n",
        "    #print(logits.shape)\n",
        "\n",
        "    return logits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D2Ej05v10z9P"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import logging\n",
        "import os\n",
        "import torch\n",
        "\n",
        "#import torch.nn.functional as F\n",
        "import numpy as np\n",
        "\n",
        "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "preds = None\n",
        "emissions = None\n",
        "out_label_ids = None\n",
        "preds_ls = []\n",
        "emission_ls = []\n",
        "out_label_ids_ls = []\n",
        "\n",
        "for i in range(len(path_list_labels)):\n",
        "    embed_filename = path_list[i]\n",
        "    target_filename = path_list_labels[i]\n",
        "    encodings = torch.load(os.path.join(path,embed_filename))\n",
        "    labels = torch.load(os.path.join(path1,target_filename))\n",
        "\n",
        "    #we need encodings, support_encodings, support_IO_labels from SANER!\n",
        "    nn_preds, nn_emissions = nn_decode(encodings, support_encodings, support_IO_labels)\n",
        "    if preds is None:\n",
        "        preds = nn_preds.detach().cpu().numpy()\n",
        "        emissions = nn_emissions.detach().cpu().numpy()\n",
        "        out_label_ids = labels.detach().cpu().numpy()\n",
        "        preds_ls.append(preds.reshape(-1))\n",
        "        emission_ls.append(emissions.reshape(-1))\n",
        "        out_label_ids_ls.append(out_label_ids.reshape(-1))\n",
        "    else:\n",
        "        preds_ls.append(nn_preds.detach().cpu().numpy().reshape(-1))\n",
        "        emission_ls.append(nn_emissions.detach().cpu().numpy().reshape(-1))\n",
        "        out_label_ids_ls.append(labels.detach().cpu().numpy().reshape(-1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrf6Bde61A1k",
        "outputId": "e9baaf2b-ef8f-449c-c159-426f41ff09f4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "184\n"
          ]
        }
      ],
      "source": [
        "print(len(preds_ls))\n",
        "\n",
        "out_label_list = [[] for _ in range(len(out_label_ids_ls))]\n",
        "preds_list = [[] for _ in range(len(out_label_ids_ls))]\n",
        "\n",
        "for i in range(len(out_label_ids_ls)):\n",
        "  for j in range(out_label_ids_ls[i].shape[0]):\n",
        "    out_label_list[i].append(label_map[out_label_ids_ls[i][j]])\n",
        "    preds_list[i].append(IO_label_map[preds_ls[i][j]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d70GtV2s1DPO"
      },
      "source": [
        "**[NOTE10]** Finally, we will get the results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gMELVVTZvJ8M"
      },
      "outputs": [],
      "source": [
        "print(preds_ls)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Y0xt1H91FBw",
        "outputId": "0c1a2193-6a34-4c24-9ca0-38acc494dedd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'precision': 0.14411163761248533, 'recall': 0.3379549393414211, 'f1': 0.20206022187004755}\n"
          ]
        }
      ],
      "source": [
        "from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "\n",
        "results = {\n",
        "    \"precision\": precision_score(out_label_list, preds_list),\n",
        "    \"recall\": recall_score(out_label_list, preds_list),\n",
        "    \"f1\": f1_score(out_label_list, preds_list),\n",
        "}\n",
        "print(results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zXVctKRyTF0s"
      },
      "source": [
        "find most similar words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9DJzclGZrbVS"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from nltk.corpus import brown\n",
        "model = gensim.models.Word2Vec(brown.sents())\n",
        "model.most_similar(positive=['drug'], topn = 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MW_Po2K5sb7_"
      },
      "outputs": [],
      "source": [
        "model.most_similar(positive=['patient'], topn = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nzQbyrwAtMgQ",
        "outputId": "362bc715-e3ea-4b8a-dae5-2a5ace6c72c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['The', 'Fulton', 'County', 'Grand', 'Jury', 'said', 'Friday', 'an', 'investigation', 'of', \"Atlanta's\", 'recent', 'primary', 'election', 'produced', '``', 'no', 'evidence', \"''\", 'that', 'any', 'irregularities', 'took', 'place', '.'], ['The', 'jury', 'further', 'said', 'in', 'term-end', 'presentments', 'that', 'the', 'City', 'Executive', 'Committee', ',', 'which', 'had', 'over-all', 'charge', 'of', 'the', 'election', ',', '``', 'deserves', 'the', 'praise', 'and', 'thanks', 'of', 'the', 'City', 'of', 'Atlanta', \"''\", 'for', 'the', 'manner', 'in', 'which', 'the', 'election', 'was', 'conducted', '.'], ...]\n"
          ]
        }
      ],
      "source": [
        "print(brown.sents())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wQIlP1CptchV"
      },
      "outputs": [],
      "source": [
        "mimic_sents = []\n",
        "tmp =[]\n",
        "\n",
        "with open(\"/content/SANER/data/sampleSet/train.txt\",\"r\") as f:\n",
        "  text = f.readlines()\n",
        "  for line in text:\n",
        "    new_line = line.strip(\"\\n\").split(\" \")\n",
        "    #print(new_line[0])\n",
        "    tmp.append(new_line[0])\n",
        "    if(line==\"\\n\"):\n",
        "      mimic_sents.append(tmp)\n",
        "      tmp = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfPYP8RNuD8-",
        "outputId": "96a7a783-8a1f-40d9-9cfc-c771d9052c11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[['HISTORY', 'OF', 'PRESENT', 'ILLNESS', '76', 'yo', 'F', 'walking', 'to', 'dentists', 'office', '3-22', 'and', 'had', 'SOB/CP/diaphoresis', ''], ['Pt', 'was', 'alert', 'upon', 'ems', 'arrival', 'and', 'became', 'unresponsive', 'enroute', 'to', 'hospital', ''], ['The', 'patient', 'was', 'readmitted', 'to', 'the', 'hospital', 'on', '2195-6-6', 'due', 'to', 'fevers', 'to', '103', 'at', 'the', 'rehabilitation', 'facility', 'despite', 'being', 'on', 'intravenous', 'antibiotics', ''], ['HISTORY', 'OF', 'PRESENT', 'ILLNESS', '55', 'year-old', 'female', 'presents', 'with', '2/5', 'week', 'history', 'of', 'non-bloody', 'diarrhea', ''], ['Today', 'he', 'slept', 'throughout', 'the', 'day', 'and', 'had', 'some', 'urinary', 'frequency/urgency', 'in', 'the', 'morning', 'that', 'resolved', 'this', 'afternoon', ''], ['This', 'morning', ',', 'he', 'took', 'all', 'his', 'medications', 'and', 'his', 'blood', 'pressures', 'have', 'been', 'in', 'the', 'SBP90s', ''], ['He', 'did', 'take', 'one', 'tablet', 'of', 'the', 'Cipro', 'this', 'afternoon', 'and', 'stated', 'he', 'felt', 'somewhat', 'better', ''], ['Upon', 'transfer', 'to', 'the', 'medical', 'floor', ',', 'vitals', 'were', 'T', '98.1', 'P', '88', 'BP', '103/45', 'RR', '25', 'SaO2', '95%', 'on', '2L', 'NC', 'does', 'not', 'use', 'oxygen', 'at', 'home', '.', ''], ['HISTORY', 'OF', 'PRESENT', 'ILLNESS', '82', 'year', 'old', 'male', 'with', 'past', 'medical', 'history', 'of', 'coronary', 'artery', 'disease', ',', 'atrial', 'fibrillation', ',', 'type', '2', 'diabetes', ',', 'BPH', ',', 'chronic', 'kidney', 'disease', 'and', 'gout', 'who', 'presents', 'with', 'intermittent', 'confusion', 'and', 'high', 'fevers', ''], ['At', 'the', 'he', 'endorsed', 'urinating', 'frequently', 'but', 'small', 'amounts', 'each', 'time', 'urgency', 'He', 'presented', 'to', 'the', 'Hospital1', '18', 'and', 'was', 'found', 'on', 'urinalysis', 'to', 'have', 'a', 'UTI', ''], ['He', 'was', 'discharged', 'on', 'Macrobid', '100mg', 'twice', 'daily', 'X', '7', 'days', ''], ['The', \"patient's\", 'wife', 'was', 'Name', 'NI', '653', 'by', 'the', 'Name', 'NI', 'QA', 'via', 'Name', 'NI', '595', 'interpreter', 'and', 'Cipro', '250mg', 'tablets', 'daily', 'X', '7', 'days', 'was', 'prescribed', ''], ['In', 'the', 'the', \"patient's\", 'son', 'has', 'been', 'calling', 'to', 'check', 'in', 'on', 'him', 'and', 'found', 'him', 'progressively', 'lethargic', ',', 'dizzy', 'and', 'intermittently', 'unable', 'to', 'urinate', ''], ['Labs', 'included', 'HCT', '37', ',', 'unremarkable', 'CEs', 'and', 'LFTs', ''], ['Pt', 'was', 'alert', 'upon', 'ems', 'arrival', 'and', 'became', 'unresponsive', 'enroute', 'to', 'hospital', ''], ['The', 'patient', 'was', 'noted', 'to', 'have', 'decreased', 'responsiveness', 'post', 'code', 'attributed', 'to', 'anoxic', 'brain', 'injury', 'per', 'neurology', ''], ['She', 'was', 'recently', 'seen', 'by', 'her', 'Primary', 'Care', 'Physician', 'for', 'evaluation', 'of', 'diarrhea', 'and', 'by', 'report', 'stool', 'O&P', 'cultures', 'were', 'negative', '.', ''], ['Please', 'refer', 'additional', 'past', 'medical', 'past', 'surgical', 'facial', 'and', 'social', 'history', 'to', 'the', 'initial', 'note', 'on', '2171-11-4', ''], ['I', 'last', 'saw', 'him', 'on', '2149-11-17', 'and', 'his', 'head', 'CT', 'showed', 'growth', 'of', 'the', 'left', 'sphenoid', 'meningioma', ''], ['HISTORY', 'OF', 'PRESENT', 'ILLNESS', 'Patient', 'is', 'a', '65-year-old', 'man', 'recently', 'evaluated', 'for', 'worsening', 'dyspnea', 'on', 'exertion', ''], ['HISTORY', 'OF', 'PRESENT', 'ILLNESS', 'This', 'is', 'an', '84-year-old', 'male', 'referred', 'to', 'Dr', ''], ['HISTORY', 'OF', 'PRESENT', 'ILLNESS', '45', 'yo', 'man', 'with', 'h/o', 'HIV', 'who', 'p/w', '4', 'days', 'of', 'cough', 'productive', 'of', 'brown', 'sputum', ',', 'as', 'well', 'as', 'left', 'sided', 'pleuritic', 'CP', '']]\n"
          ]
        }
      ],
      "source": [
        "print(mimic_sents)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUco5rBQui6s"
      },
      "outputs": [],
      "source": [
        "import gensim\n",
        "from nltk.corpus import brown\n",
        "model = gensim.models.Word2Vec(mimic_sents)\n",
        "#model.most_similar(positive=['drug'], topn = 10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvofrTrzulnN"
      },
      "outputs": [],
      "source": [
        "model.most_similar(positive=['to'], topn = 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdfb3bLQvwTG",
        "outputId": "6c2881ee-91e1-4d0b-d420-6a2776d944e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[==================================================] 100.0% 104.8/104.8MB downloaded\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[('facebook', 0.9480051398277283),\n",
              " ('tweet', 0.9403422474861145),\n",
              " ('fb', 0.9342358708381653),\n",
              " ('instagram', 0.9104823470115662),\n",
              " ('chat', 0.8964964747428894),\n",
              " ('hashtag', 0.8885936141014099),\n",
              " ('tweets', 0.8878157734870911),\n",
              " ('tl', 0.8778461813926697),\n",
              " ('link', 0.877821147441864),\n",
              " ('internet', 0.8753897547721863)]"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import gensim.downloader\n",
        "glove_vectors = gensim.downloader.load('glove-twitter-25')\n",
        "glove_vectors.most_similar('twitter')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pysyG7vRwr4-",
        "outputId": "0b587984-c24f-45b5-a9a0-83a6b62d3346"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[('bronchitis', 0.8888662457466125),\n",
              " ('poisoning', 0.8864762783050537),\n",
              " ('seizure', 0.8779582977294922),\n",
              " ('strep', 0.8676226735115051),\n",
              " ('cured', 0.8565991520881653),\n",
              " ('choking', 0.8544393181800842),\n",
              " ('asthma', 0.849441647529602),\n",
              " ('hives', 0.8472653031349182),\n",
              " ('heartburn', 0.845150351524353),\n",
              " ('hiccups', 0.8438467979431152)]"
            ]
          },
          "execution_count": 70,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "glove_vectors.most_similar('diarrhea')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}