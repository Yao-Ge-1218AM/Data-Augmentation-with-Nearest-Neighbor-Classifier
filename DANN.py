# -*- coding: utf-8 -*-
"""Copy of SANER+NNShot(clean).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1F81UtJnCafgkFRsHk6W40YfjOqweScXs
"""

!git clone https://github.com/cuhksz-nlp/SANER

"""2023 Jan: torch==1.5.1
2023 Nov: torch==2.1.0
"""

!pip install torch==2.2.1

!pip install spacy

!pip install tqdm==4.48.0

!pip install fastNLP==0.5

!pip install word2vec==0.9.4

!wget https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-cased.tar.gz

!tar -xzvf /content/bert-large-cased.tar.gz

"""try biobert and clinical-bert"""

!wget http://nlp.dmis.korea.edu/projects/biobert-2020-checkpoints/biobert_large_v1.1_pubmed.tar.gz

!tar -xzvf /content/biobert_large_v1.1_pubmed.tar.gz

!wget -O umlsbert.tar.xz https://www.dropbox.com/s/kziiuyhv9ile00s/umlsbert.tar.xz?dl=0

!tar -xvf umlsbert.tar.xz

cd /content/

!gdown --id '11ctw2nw0NQ811_4uBA86670yPk_YgsUe'

!gdown --id '1CG2nEpfPm3rWVhEjr-dkS7DWENmxSl8v'

"""**[NOTE1]** After decompression "bert-large-cased.tar.gz", we will get two files: "bert_config.json" and "pytorch_model.bin", but we don't have the file "vocab.txt". So we need to:

1. Create a new folder under the *SANER/data* folder and name it "bert-large-cased";

2. Upload the file "vocab.txt" into this bert folder;

3. Move files "bert_config.json" and "pytorch_model.bin" to this bert folder.
"""

cd SANER/

"""**[NOTE2]** If we want to run SANER (itself), we also need to:

1. Upload the file "glove.100" into the folder SANER/data

2. Create a new folder under the SANER folder and name it "log"

3. Change the path in "train_bert_elmo_en.py" line 122 - line 136 with the code in cell below
"""

!mkdir log

!mkdir /content/SANER/data/bert-large-cased/

!mv /content/bert_config.json /content/SANER/data/bert-large-cased/

!mv /content/pytorch_model.bin /content/SANER/data/bert-large-cased/

!mv /content/vocab.txt /content/SANER/data/bert-large-cased/

!mv /content/glove.100d.txt /content/SANER/data/

from google.colab import drive
drive.mount('/content/drive')

drive.mount("/content/drive", force_remount=True)

"""/content/SANER/train_bert_elmo_en.py"""

!cp /content/drive/MyDrive/glove.100d.txt /content/SANER/data

paths = {
    "train": "../SANER/data/{}/train.txt".format(dataset),
    "test": "../SANER/data/{}/test.txt".format(dataset),
    "dev": "../SANER/data/{}/dev.txt".format(dataset)
}
data = WNUT_17NERPipe(encoding_type=encoding_type).process_from_file(paths)

dict_save_path = os.path.join("../SANER/data/{}/data.pth".format(dataset))
context_dict, context_word2id, context_id2word = get_neighbor_for_vocab(
    data.get_vocab('words').word2idx, glove_path, dict_save_path
)

train_feature_data, dev_feature_data, test_feature_data = build_instances(
    "../SANER/data/{}".format(dataset), context_num, context_dict
)

"""**[NOTE3]** Now we can run SANER.

Some tips:

1. The default folder for input data (train/dev/test) is /SANER/data/sampleSet

2. There is a special point, we need to leave two blank lines at the end of train/dev/test, otherwise an error will be reported.

3. If we want to run again totaly, we need to delete two folders: "SANER/caches" and "SANER/ckpt"

**bug1:** one possible error:         _VF._pack_padded_sequence(input, lengths.cpu(), batch_first)

/usr/local/lib/python3.10/dist-packages/torch/nn/utils/rnn.py

line 264
"""

!unzip /content/elmo_en_Original.zip

!unzip /content/drive/MyDrive/elmo_en_Original.zip -d /content/SANER/

"""**bug2:** *line* 68:         model_dir_or_name = "/content/SANER/elmo_en_Original/"

/content/SANER/fastNLP/embeddings/elmo_embedding.py

**bug3:** module 'numpy' has no attribute 'float'. ???*italicized text*

/usr/local/lib/python3.10/dist-packages/word2vec/wordvectors.py

line 237，244

**bug4:** embed.weight.data[len(new_word_piece_vocab)] = original_embed[self.tokenzier.vocab[token]]
IndexError: index 29627 is out of bounds for dimension 0 with size 28996

尝试换了vocab.txt, size = 213,450 bytes

/content/SANER/fastNLP/embeddings/bert_embedding.py

line 314:         self.word_to_wordpieces = np.array(word_to_wordpieces, dtype=object)

**Predictions:**

/content/SANER/fastNLP/core/metrics.py

metrics: line 689,找到prediction

last epoch才存：

open_count = 0

global open_count
open_count += 1

if(open_count>11195):
  with open("/content/SANER/predictions-cdr-gpt-parents.txt", "a") as wf:
    wf.write(' '.join(pred_str_tags) + "\n")

open_count>11195, 11195x49 = 548555, cdr

open_count>821, 821x49=40229, mimic3

open_count>536, 536x49=26264, impacts

open_count>156, 156x49=7644, blood pressure; 269x45=12105

open_count>33171, 110x49=1625379, 1634119,medmentions

200，200x49，ncbi
"""

!zip -r /content/SANER.zip /content/SANER/

!cp /content/SANER.zip /content/drive/MyDrive/

!unzip /content/drive/MyDrive/SANER.zip -d /content/SANER/

import torch
torch.cuda.empty_cache()

PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True

cd /content/SANER

!python3 /content/SANER/run.py

!rm -r /content/SANER/caches
!rm -r /content/SANER/ckpt

"""**[NOTE4]** If we want to get the embeddings from SANER (after data augmentation), we need to:

1. Obtain the labels first: we can add "print(tgt_vocab.word2idx)" at SANER/fastNLP/io/pipe/utils.py: line 132

2. Add codes for saving embeddings of training data / test data, training data's target / test data's target. In the cell below, I marked where each piece of code needs to be inserted.


"""

import datetime #No need to import datetime in trainer.py

#/content/SANER/models/TENER.py: line 297
time1 = datetime.datetime.now()
print("Embed-Test: +++++++++++++++++",time1)
path1 = "/content/test/test-embed-" + str(time1) + ".pt"
torch.save(logits, path1)

#/content/SANER/models/TENER.py: line 300
time2 = datetime.datetime.now()
path2 = "/content/train/train-embed-" + str(time2) + ".pt"
torch.save(logits, path2)

#/content/SANER/fastNLP/core/trainer.py: line 790
time3 = datetime.now()
path3 = "/content/target-train/train-label-" + str(time3) + ".pt"
torch.save(batch_y['target'], path3)

#/content/SANER/fastNLP/core/tester.py: line 238
time4 = datetime.datetime.now()
path4 = "/content/target/test-label-" + str(time4) + ".pt"
torch.save(batch_y['target'], path4)

!mkdir /content/train/
!mkdir /content/test/
!mkdir /content/target/
!mkdir /content/target-train/

!rm -r /content/train/
!rm -r /content/test/
!rm -r /content/target/
!rm -r /content/target-train/

"""**[NOTE5]** After this, it's some code I wrote to find the saved embeddings and their labels of last epoch, as well as the code to calculate the similarity, it may be bad, and there is some hard code, I feel so sorry for that!

**[NOTE6]** First, since we have 50 epoches and we only need the embeddings after last epoch.

1. For training data, we only need to choose the last one we saved, including the embeddings for training data and targets.

2. For test data, I print the time for it. So I use the time to select which embedding is from the last epoch.
"""

!mkdir /content/test-new/
!mkdir /content/test-new1/

!rm -r /content/test-new/
!rm -r /content/test-new1/

import os
import shutil

filePath = "/content/test/"
new_filePath = "/content/test-new/"
os.listdir(filePath)
filelist = os.listdir(filePath)
count = 0

for file in filelist:
  h = int(file[22:24])  #time of hour
  m = int(file[25:27])  #time of minute
  s = int(file[28:30])  #time of second
  # if the output is : Embed-Test: +++++++++++++++++ 2022-05-13 00:42:33.338923
  # so h is 0, m is 42 and s is 33.
  if(h==4 and ((m==29 and s>=40) or m>29)):
    count+=1
    shutil.copyfile(filePath + file, new_filePath + file)
print(count)

cd /content/

!tar -zcvf test-embed-bc5cdr-siblings.tar.gz /content/test-new/

!tar -xzvf /content/test-embed-n2c2-5shot-lstm.tar.gz

import os
import shutil

filePath = "/content/test-new/"
new_filePath = "/content/test-new1/"
os.listdir(filePath)
filelist = os.listdir(filePath)

for file in filelist:
  shutil.copyfile(filePath + file, new_filePath + file[25:27] + file[28:30] + file[31:-3] + ".pt")

import os
path = '/content/test-new1/'

path_list = os.listdir(path)
path_list.sort(key=lambda x:int(x.split('.')[0]))

print(path_list)

!mkdir /content/target-new/
!mkdir /content/target-new1/

!rm -r /content/target-new/
!rm -r /content/target-new1/

import os
import shutil

filePath = "/content/target/"
new_filePath = "/content/target-new/"
os.listdir(filePath)
filelist = os.listdir(filePath)
count = 0

for file in filelist:
  h = int(file[22:24])
  m = int(file[25:27])
  s = int(file[28:30])
  #print(file, h,m)
  if(h==4 and ((m==29 and s>=40) or m>29)):
    count+=1
    shutil.copyfile(filePath + file, new_filePath + file)
print(count)

!tar -zcvf test-labels-bc5cdr-siblings.tar.gz /content/target-new/

!tar -xzvf /content/test-labels-i2b2-1shot-top2_dont_need.tar.gz

import os
import shutil

filePath = "/content/target-new/"
new_filePath = "/content/target-new1/"
os.listdir(filePath)
filelist = os.listdir(filePath)

for file in filelist:
  shutil.copyfile(filePath + file, new_filePath + file[25:27] + file[28:30] + file[31:-3] + ".pt")

import os
path1 = '/content/target-new1/'

path_list_labels = os.listdir(path1)
path_list_labels.sort(key=lambda x:int(x.split('.')[0]))

print(path_list_labels)

path_list = path_list[1:]
path_list_labels = path_list_labels[1:]

path_list_labels = path_list_labels[2:]

print(len(path_list))
print(len(path_list_labels))

"""**[NOTE7]** Then we can try NNShot."""

!pip install seqeval

"""**[NOTE7]** We need to get the embeddings of training data."""

import torch
support_encodings = torch.load('/content/train/train-embed-2023-03-14 04:27:15.685682.pt') #the last one in /content/train
print(support_encodings.shape)

import torch
support_labels = torch.load('/content/target-train/train-label-2023-03-14 04:27:15.101574.pt')
print(support_labels.shape)
print(support_labels)

"""**[NOTE8]** Then, We need to get the embeddings of training data's labels, and transfer the labels from BIOES to IO. Here I used some hard code :( , I weill use N2C2 data as an example.

  1. We need: "target_labels", and "reversed_label_map". Then we can get "label_map".

  2. Then we need to transfer the labels from BIOES to IO, but actually, only need to change the number. That means we need to change the number (which represents label) from "reversed_label_map" to "reversed_IO_map".
"""

#bc5cdr
target_labels = ['O', 'S-Chemical', 'S-Disease', 'B-Disease', 'E-Disease', 'I-Disease', 'B-Chemical', 'E-Chemical', 'I-Chemical']

target_labels = ['O', 'S-DATE', 'B-DOCTOR', 'E-DOCTOR', 'S-DOCTOR', 'S-AGE',
 'S-PATIENT', 'S-HOSPITAL', 'B-HOSPITAL', 'E-HOSPITAL', 'B-PATIENT',
 'E-PATIENT', 'S-MEDICALRECORD', 'B-DATE', 'E-DATE', 'I-HOSPITAL',
 'I-DOCTOR', 'I-DATE', 'S-CITY', 'S-STATE', 'I-STREET',
 'S-ZIP', 'B-STREET', 'E-STREET', 'S-PHONE', 'S-COUNTRY',
 'S-IDNUM', 'S-USERNAME', 'B-PROFESSION', 'E-PROFESSION', 'S-PROFESSION',
 'B-CITY', 'E-CITY', 'I-PROFESSION', 'B-PHONE', 'E-PHONE',
 'B-ORGANIZATION', 'E-ORGANIZATION', 'S-ORGANIZATION', 'I-PATIENT', 'I-ORGANIZATION',
 'B-STATE', 'E-STATE', 'B-COUNTRY', 'E-COUNTRY', 'B-MEDICALRECORD',
 'E-MEDICALRECORD', 'B-LOCATIONOTHER', 'E-LOCATIONOTHER', 'I-MEDICALRECORD', 'I-COUNTRY',
 'I-CITY', 'S-LOCATIONOTHER', 'I-URL', 'S-EMAIL', 'S-BIOID',
 'B-HEALTHPLAN', 'E-HEALTHPLAN', 'B-URL', 'E-URL', 'S-FAX',
 'B-FAX', 'E-FAX', 'B-IDNUM', 'E-IDNUM', 'B-AGE',
 'E-AGE', 'B-DEVICE', 'E-DEVICE']

target_labels = ['O', 'S-Drug', 'S-Form', 'S-Route', 'B-Strength', 'E-Strength', 'S-Frequency', 'S-Reason', 'B-Dosage', 'E-Dosage', 'S-Dosage', 'I-Frequency', 'S-Strength', 'B-Frequency', 'E-Frequency', 'B-Reason', 'E-Reason', 'B-Drug', 'E-Drug', 'I-Reason', 'S-ADE', 'B-Duration', 'E-Duration', 'B-Form', 'E-Form', 'I-Duration', 'B-ADE', 'E-ADE', 'B-Route', 'E-Route', 'I-Strength', 'I-ADE', 'I-Drug', 'I-Form', 'I-Dosage', 'S-Duration', 'I-Route']

target_labels = ['O', 'S-DATE', 'B-DOCTOR', 'E-DOCTOR', 'S-DOCTOR', 'S-AGE', 'S-PATIENT', 'S-HOSPITAL', 'B-PATIENT', 'E-PATIENT', 'B-HOSPITAL', 'E-HOSPITAL', 'S-MEDICALRECORD', 'B-DATE', 'E-DATE', 'I-HOSPITAL', 'I-DOCTOR', 'I-DATE', 'S-CITY', 'S-STATE', 'I-STREET', 'S-ZIP', 'B-STREET', 'E-STREET', 'S-PHONE', 'S-COUNTRY', 'S-IDNUM', 'S-USERNAME', 'B-PROFESSION', 'E-PROFESSION', 'S-PROFESSION', 'B-CITY', 'E-CITY', 'B-ORGANIZATION', 'E-ORGANIZATION', 'I-PROFESSION', 'B-PHONE', 'E-PHONE', 'S-ORGANIZATION', 'I-PATIENT', 'I-ORGANIZATION', 'B-STATE', 'E-STATE', 'B-LOCATIONOTHER', 'E-LOCATIONOTHER', 'B-COUNTRY', 'E-COUNTRY', 'B-MEDICALRECORD', 'E-MEDICALRECORD', 'I-MEDICALRECORD', 'S-DEVICE', 'S-FAX', 'I-LOCATIONOTHER', 'S-EMAIL', 'I-COUNTRY', 'I-CITY', 'S-LOCATIONOTHER', 'B-HEALTHPLAN', 'E-HEALTHPLAN', 'B-URL', 'I-URL', 'E-URL', 'S-BIOID', 'B-FAX', 'E-FAX', 'B-IDNUM', 'E-IDNUM', 'B-AGE', 'E-AGE', 'B-DEVICE', 'E-DEVICE']

target_labels = ['O', 'I-SYMPTOM', 'B-SYMPTOM', 'E-SYMPTOM', 'I-MEASUREMENT', 'S-SYMPTOM', 'B-MEASUREMENT', 'E-MEASUREMENT', 'S-EVENT', 'S-DRUG', 'B-LOCATION', 'E-LOCATION', 'B-EVENT', 'E-EVENT', 'I-EVENT', 'B-AMOUNT', 'E-AMOUNT', 'I-TIME', 'I-LOCATION', 'B-TIME', 'E-TIME', 'S-LOCATION', 'I-AMOUNT', 'S-AGE', 'S-AMOUNT', 'S-GENDER', 'S-MEASUREMENT', 'B-DRUG', 'E-DRUG', 'S-ORGANIZATION', 'S-TIME', 'S-FREQUENCY', 'B-ORGANIZATION', 'E-ORGANIZATION', 'B-FREQUENCY', 'E-FREQUENCY', 'I-ORGANIZATION', 'B-AGE', 'E-AGE', 'I-DRUG', 'S-DATE', 'I-FREQUENCY']

label_map = {i: label for i, label in enumerate(target_labels)}
print(label_map)

target_labels = ['O', 'S-Drug', 'S-Form', 'S-Route', 'B-Strength', 'E-Strength', 'S-Frequency', 'S-Reason', 'B-Dosage', 'E-Dosage', 'S-Dosage', 'I-Frequency', 'S-Strength', 'B-Frequency', 'E-Frequency', 'B-Reason', 'E-Reason', 'B-Drug', 'E-Drug', 'I-Reason', 'S-ADE', 'B-Duration', 'E-Duration', 'B-Form', 'E-Form', 'I-Duration', 'B-ADE', 'E-ADE', 'B-Route', 'E-Route', 'I-Strength', 'I-ADE', 'I-Drug', 'I-Form', 'I-Dosage', 'S-Duration', 'I-Route']

reversed_label_map = {'O': 0, 'S-Drug': 1, 'S-Form': 2, 'S-Route': 3, 'B-Strength': 4, 'E-Strength': 5, 'S-Frequency': 6, 'S-Reason': 7, 'B-Dosage': 8, 'E-Dosage': 9, 'S-Dosage': 10, 'I-Frequency': 11, 'S-Strength': 12, 'B-Frequency': 13, 'E-Frequency': 14, 'B-Reason': 15, 'E-Reason': 16, 'B-Drug': 17, 'E-Drug': 18, 'I-Reason': 19, 'S-ADE': 20, 'B-Duration': 21, 'E-Duration': 22, 'B-Form': 23, 'E-Form': 24, 'I-Duration': 25, 'B-ADE': 26, 'E-ADE': 27, 'B-Route': 28, 'E-Route': 29, 'I-Strength': 30, 'I-ADE': 31, 'I-Drug': 32, 'I-Form': 33, 'I-Dosage': 34, 'S-Duration': 35, 'I-Route': 36}

#bc5cdr
def bioes2io(target):
        x_num,y_num = target.shape
        for i in range(x_num):
              for j in range(y_num):
                if(target[i][j]==1 or target[i][j]==6 or target[i][j]==7 or target[i][j]==8):
                  target[i][j] = 1
                if(target[i][j]==2 or target[i][j]==3 or target[i][j]==4 or target[i][j]==5):
                  target[i][j] = 2
        return target

#TANER 361
#support_encodings = support_labels
#print(x_num,y_num)
support_IO_labels = bioes2io(support_labels)
#print(support_IO_labels)
n,p = support_labels.shape
support_IO_labels = support_IO_labels.reshape(n*p)
print(support_IO_labels.shape)
print(support_IO_labels)

#TENER line 271
def bioes2io(target):
        x_num,y_num = target.shape
        for i in range(x_num):
              for j in range(y_num):
                if(target[i][j]==1 or target[i][j]==2 or target[i][j]==3 or target[i][j]==5):
                  target[i][j] = 1
                if(target[i][j]==4 or target[i][j]==6 or target[i][j]==7 or target[i][j]==26):
                  target[i][j] = 2
                if(target[i][j]==8 or target[i][j]==12 or target[i][j]==13 or target[i][j]==14):
                  target[i][j] = 3
                if(target[i][j]==9 or target[i][j]==27 or target[i][j]==28 or target[i][j]==39):
                  target[i][j] = 4
                if(target[i][j]==10 or target[i][j]==11 or target[i][j]==18 or target[i][j]==21):
                  target[i][j] = 5
                if(target[i][j]==15 or target[i][j]==16 or target[i][j]==22 or target[i][j]==24):
                  target[i][j] = 6
                if(target[i][j]==23 or target[i][j]==37 or target[i][j]==38):
                  target[i][j] = 8
                if(target[i][j]==19 or target[i][j]==17 or target[i][j]==20 or target[i][j]==30):
                  target[i][j] = 7
                if(target[i][j]==25):
                  target[i][j] = 9
                if(target[i][j]==29 or target[i][j]==32 or target[i][j]==33 or target[i][j]==36):
                  target[i][j] = 10
                if(target[i][j]==31 or target[i][j]==34 or target[i][j]==35 or target[i][j]==41):
                  target[i][j] = 11
                if(target[i][j]==40):
                  target[i][j] = 12
        return target

#TANER 361
#support_encodings = support_labels
#print(x_num,y_num)
support_IO_labels = bioes2io(support_labels)
#print(support_IO_labels)
n,p = support_labels.shape
support_IO_labels = support_IO_labels.reshape(n*p)
print(support_IO_labels.shape)
print(support_IO_labels)

#TENER line 271
def bioes2io(target):
        x_num,y_num = target.shape
        for i in range(x_num):
              for j in range(y_num):
                if(target[i][j]==1 or target[i][j]==17 or target[i][j]==18 or target[i][j]==32):
                  target[i][j] = 1
                if(target[i][j]==2 or target[i][j]==23 or target[i][j]==24 or target[i][j]==33):
                  target[i][j] = 2
                if(target[i][j]==3 or target[i][j]==28 or target[i][j]==29 or target[i][j]==36):
                  target[i][j] = 3
                if(target[i][j]==4 or target[i][j]==5 or target[i][j]==12 or target[i][j]==30):
                  target[i][j] = 4
                if(target[i][j]==6 or target[i][j]==11 or target[i][j]==13 or target[i][j]==14):
                  target[i][j] = 5
                if(target[i][j]==7 or target[i][j]==15 or target[i][j]==16 or target[i][j]==19):
                  target[i][j] = 6
                if(target[i][j]==8 or target[i][j]==9 or target[i][j]==10 or target[i][j]==34):
                  target[i][j] = 7
                if(target[i][j]==20 or target[i][j]==26 or target[i][j]==27 or target[i][j]==31):
                  target[i][j] = 8
                if(target[i][j]==21 or target[i][j]==22 or target[i][j]==25 or target[i][j]==35):
                  target[i][j] = 9
        return target

#TANER 361
#support_encodings = support_labels
#print(x_num,y_num)
support_IO_labels = bioes2io(support_labels)
#print(support_IO_labels)
n,p = support_labels.shape
support_IO_labels = support_IO_labels.reshape(n*p)
print(support_IO_labels.shape)
print(support_IO_labels)

#TENER line 271
def bioes2io(target):
        x_num,y_num = target.shape
        for i in range(x_num):
              for j in range(y_num):
                if(target[i][j]==1 or target[i][j]==14 or target[i][j]==13 or target[i][j]==17):
                  target[i][j] = 14
                if(target[i][j]==2 or target[i][j]==3 or target[i][j]==4 or target[i][j]==16):
                  target[i][j] = 2
                if(target[i][j]==5 or target[i][j]==66 or target[i][j]==65):
                  target[i][j] = 13
                if(target[i][j]==6 or target[i][j]==10 or target[i][j]==11 or target[i][j]==39):
                  target[i][j] = 1
                if(target[i][j]==7 or target[i][j]==8 or target[i][j]==9 or target[i][j]==15):
                  target[i][j] = 5
                if(target[i][j]==12 or target[i][j]==45 or target[i][j]==46 or target[i][j]==49):
                  target[i][j] = 20
                if(target[i][j]==18 or target[i][j]==31 or target[i][j]==32 or target[i][j]==51):
                  target[i][j] = 8
                if(target[i][j]==19 or target[i][j]==41 or target[i][j]==42):
                  target[i][j] = 9
                if(target[i][j]==25 or target[i][j]==43 or target[i][j]==44 or target[i][j]==50):
                  target[i][j] = 10
                if(target[i][j]==21):
                  target[i][j] = 11
                if(target[i][j]==22 or target[i][j]==23 or target[i][j]==20):
                  target[i][j] = 7
                if(target[i][j]==24 or target[i][j]==35 or target[i][j]==34):
                  target[i][j] = 15
                if(target[i][j]==27):
                  target[i][j] = 3
                if(target[i][j]==26 or target[i][j]==64 or target[i][j]==63):
                  target[i][j] = 21
                if(target[i][j]==28 or target[i][j]==29 or target[i][j]==30 or target[i][j]==33):
                  target[i][j] = 4
                if(target[i][j]==37 or target[i][j]==36 or target[i][j]==38 or target[i][j]==40):
                  target[i][j] = 6
                if(target[i][j]==48 or target[i][j]==47 or target[i][j]==52):
                  target[i][j] = 12
                if(target[i][j]==53 or target[i][j]==59 or target[i][j]==58):
                  target[i][j] = 18
                if(target[i][j]==54):
                  target[i][j] = 17
                if(target[i][j]==55):
                  target[i][j] = 23
                if(target[i][j]==56 or target[i][j]==57):
                  target[i][j] = 19
                if(target[i][j]==62 or target[i][j]==60 or target[i][j]==61):
                  target[i][j] = 16
                if(target[i][j]==67 or target[i][j]==68):
                  target[i][j] = 22
        return target

#TANER 361
#support_encodings = support_labels
#print(x_num,y_num)
support_IO_labels = bioes2io(support_labels)
#print(support_IO_labels)
n,p = support_labels.shape
support_IO_labels = support_IO_labels.reshape(n*p)
print(support_IO_labels.shape)
print(support_IO_labels)

#TENER line 271
def bioes2io(target):
        x_num,y_num = target.shape
        for i in range(x_num):
              for j in range(y_num):
                if(target[i][j]==1 or target[i][j]==2 or target[i][j]==3 or target[i][j]==5):
                  target[i][j] = 1
                if(target[i][j]==4 or target[i][j]==6 or target[i][j]==7 or target[i][j]==26):
                  target[i][j] = 2
                if(target[i][j]==8 or target[i][j]==12 or target[i][j]==13 or target[i][j]==14):
                  target[i][j] = 3
                if(target[i][j]==9 or target[i][j]==27 or target[i][j]==28 or target[i][j]==39):
                  target[i][j] = 4
                if(target[i][j]==10 or target[i][j]==11 or target[i][j]==18 or target[i][j]==21):
                  target[i][j] = 5
                if(target[i][j]==15 or target[i][j]==16 or target[i][j]==22 or target[i][j]==24):
                  target[i][j] = 6
                if(target[i][j]==23 or target[i][j]==37 or target[i][j]==38):
                  target[i][j] = 8
                if(target[i][j]==19 or target[i][j]==17 or target[i][j]==20 or target[i][j]==30):
                  target[i][j] = 7
                if(target[i][j]==25):
                  target[i][j] = 9
                if(target[i][j]==29 or target[i][j]==32 or target[i][j]==33 or target[i][j]==36):
                  target[i][j] = 10
                if(target[i][j]==31 or target[i][j]==34 or target[i][j]==35 or target[i][j]==41):
                  target[i][j] = 11
                if(target[i][j]==40):
                  target[i][j] = 12
        return target

#TANER 361
#support_encodings = support_labels
#print(x_num,y_num)
support_IO_labels = bioes2io(support_labels)
#print(support_IO_labels)
n,p = support_labels.shape
support_IO_labels = support_IO_labels.reshape(n*p)
print(support_IO_labels.shape)
print(support_IO_labels)

#TENER line 271
def bioes2io(target):
        x_num,y_num = target.shape
        for i in range(x_num):
              for j in range(y_num):
                if(target[i][j]==1 or target[i][j]==17 or target[i][j]==18 or target[i][j]==32):
                  target[i][j] = 1
                if(target[i][j]==2 or target[i][j]==23 or target[i][j]==24 or target[i][j]==33):
                  target[i][j] = 2
                if(target[i][j]==3 or target[i][j]==28 or target[i][j]==29 or target[i][j]==36):
                  target[i][j] = 3
                if(target[i][j]==4 or target[i][j]==5 or target[i][j]==12 or target[i][j]==30):
                  target[i][j] = 4
                if(target[i][j]==6 or target[i][j]==11 or target[i][j]==13 or target[i][j]==14):
                  target[i][j] = 5
                if(target[i][j]==7 or target[i][j]==15 or target[i][j]==16 or target[i][j]==19):
                  target[i][j] = 6
                if(target[i][j]==8 or target[i][j]==9 or target[i][j]==10 or target[i][j]==34):
                  target[i][j] = 7
                if(target[i][j]==20 or target[i][j]==26 or target[i][j]==27 or target[i][j]==31):
                  target[i][j] = 8
                if(target[i][j]==21 or target[i][j]==22 or target[i][j]==25 or target[i][j]==35):
                  target[i][j] = 9
        return target

#TANER 361
#support_encodings = support_labels
#print(x_num,y_num)
support_IO_labels = bioes2io(support_labels)
#print(support_IO_labels)
n,p = support_labels.shape
support_IO_labels = support_IO_labels.reshape(n*p)
print(support_IO_labels.shape)
print(support_IO_labels)

reversed_IO_map = {'O': 0, 'I-PATIENT': 1, 'I-DOCTOR': 2, 'I-USERNAME': 3, 'I-PROFESSION': 4, 'I-HOSPITAL': 5,
'I-ORGANIZATION': 6, 'I-STREET': 7, 'I-CITY': 8, 'I-STATE': 9, 'I-COUNTRY': 10,
'I-ZIP': 11, 'I-LOCATIONOTHER': 12, 'I-AGE': 13, 'I-DATE': 14, 'I-PHONE': 15,
'I-FAX': 16, 'I-EMAIL': 17, 'I-URL': 18, 'I-HEALTHPLAN': 19,
'I-MEDICALRECORD': 20, 'I-IDNUM': 21, 'I-DEVICE': 22, 'I-BIOID': 23}

target_IO_labels = ['O', 'I-PATIENT', 'I-DOCTOR', 'I-USERNAME', 'I-PROFESSION', 'I-HOSPITAL',
'I-ORGANIZATION', 'I-STREET', 'I-CITY', 'I-STATE', 'I-COUNTRY',
'I-ZIP', 'I-LOCATIONOTHER', 'I-AGE', 'I-DATE', 'I-PHONE',
'I-FAX', 'I-EMAIL', 'I-URL', 'I-HEALTHPLAN',
'I-MEDICALRECORD', 'I-IDNUM', 'I-DEVICE', 'I-BIOID']

reversed_IO_map = {'O': 0, 'I-Drug': 1, 'I-Form': 2, 'I-Route': 3, 'I-Strength': 4, 'I-Frequency': 5,
 'I-Reason': 6, 'I-Dosage': 7, 'I-ADE': 8, 'I-Duration': 9}

target_IO_labels = {'O', 'I-Drug', 'I-Form', 'I-Route', 'I-Strength', 'I-Frequency',
 'I-Reason', 'I-Dosage', 'I-ADE', 'I-Duration'}

reversed_label_map = {'O': 0, 'S-DATE': 1, 'B-DOCTOR': 2, 'E-DOCTOR': 3, 'S-DOCTOR': 4, 'S-AGE': 5, 'S-PATIENT': 6, 'S-HOSPITAL': 7, 'B-PATIENT': 8, 'E-PATIENT': 9, 'B-HOSPITAL': 10, 'E-HOSPITAL': 11, 'S-MEDICALRECORD': 12, 'B-DATE': 13, 'E-DATE': 14, 'I-HOSPITAL': 15, 'I-DOCTOR': 16, 'I-DATE': 17, 'S-CITY': 18, 'S-STATE': 19, 'I-STREET': 20, 'S-ZIP': 21, 'B-STREET': 22, 'E-STREET': 23, 'S-PHONE': 24, 'S-COUNTRY': 25, 'S-IDNUM': 26, 'S-USERNAME': 27, 'B-PROFESSION': 28, 'E-PROFESSION': 29, 'S-PROFESSION': 30, 'B-CITY': 31, 'E-CITY': 32, 'B-ORGANIZATION': 33, 'E-ORGANIZATION': 34, 'I-PROFESSION': 35, 'B-PHONE': 36, 'E-PHONE': 37, 'S-ORGANIZATION': 38, 'I-PATIENT': 39, 'I-ORGANIZATION': 40, 'B-STATE': 41, 'E-STATE': 42, 'B-LOCATIONOTHER': 43, 'E-LOCATIONOTHER': 44, 'B-COUNTRY': 45, 'E-COUNTRY': 46, 'B-MEDICALRECORD': 47, 'E-MEDICALRECORD': 48, 'I-MEDICALRECORD': 49, 'S-DEVICE': 50, 'S-FAX': 51, 'I-LOCATIONOTHER': 52, 'S-EMAIL': 53, 'I-COUNTRY': 54, 'I-CITY': 55, 'S-LOCATIONOTHER': 56, 'B-HEALTHPLAN': 57, 'E-HEALTHPLAN': 58, 'B-URL': 59, 'I-URL': 60, 'E-URL': 61, 'S-BIOID': 62, 'B-FAX': 63, 'E-FAX': 64, 'B-IDNUM': 65, 'E-IDNUM': 66, 'B-AGE': 67, 'E-AGE': 68, 'B-DEVICE': 69, 'E-DEVICE': 70}

reversed_IO_map = {'O': 0, 'I-SYMPTOM': 1, 'I-MEASUREMENT': 2, 'I-EVENT': 3, 'I-DRUG': 4, 'I-LOCATION': 5,
 'I-AMOUNT': 6, 'I-TIME': 7, 'I-AGE': 8, 'I-GENDER': 9, 'I-ORGANIZATION': 10,
 'I-FREQUENCY': 11, 'I-DATE': 12}

target_IO_labels = ['O', 'I-SYMPTOM', 'I-MEASUREMENT', 'I-EVENT', 'I-DRUG', 'I-LOCATION',
 'I-AMOUNT', 'I-TIME', 'I-AGE', 'I-GENDER', 'I-ORGANIZATION',
 'I-FREQUENCY', 'I-DATE']

reversed_IO_map = {'O': 0, 'I-Drug': 1, 'I-Form': 2, 'I-Route': 3, 'I-Strength': 4, 'I-Frequency': 5,
 'I-Reason': 6, 'I-Dosage': 7, 'I-ADE': 8, 'I-Duration': 9}

target_IO_labels = {'O', 'I-Drug', 'I-Form', 'I-Route', 'I-Strength', 'I-Frequency',
 'I-Reason', 'I-Dosage', 'I-ADE', 'I-Duration'}

#bc5cdr
target_IO_labels = {'O', 'I-Chemical', 'I-Disease'}

IO_label_map = {i: label for i, label in enumerate(target_IO_labels)}
print(IO_label_map)
reversed_IO_map = {label: i for i, label in enumerate(target_IO_labels)}
print(reversed_IO_map)

"""**[NOTE9]** Now we can calculate the similarity!"""

import argparse
import logging
import os
import torch

import torch.nn.functional as F
import numpy as np
from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score
from torch.utils.data import DataLoader, TensorDataset
from tqdm import tqdm
from scipy import spatial

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

def nn_decode(reps, support_reps, support_tags):
    """
    NNShot: neariest neighbor decoder for few-shot NER
    """
    batch_size, sent_len, ndim = reps.shape
    scores = _euclidean_metric(reps.view(-1, ndim), support_reps.view(-1, ndim), True)
    emissions = get_nn_emissions(scores, support_tags)
    tags = torch.argmax(emissions, 1)
    return tags.view(batch_size, sent_len), emissions.view(batch_size, sent_len, -1)


def get_nn_emissions(scores, tags):
    """
    Obtain emission scores from NNShot
    """
    n, m = scores.shape
    n_tags = torch.max(tags) + 1
    emissions = -100000. * torch.ones(n, n_tags).to(scores.device)
    for t in range(n_tags):
        mask = (tags == t).float().view(1, -1).to(device)
        masked = scores * mask
        masked = torch.where(masked < 0, masked, torch.tensor(-100000.).to(scores.device))
        emissions[:, t] = torch.max(masked, dim=1)[0]
    return emissions

#def normalize(x, axis=-1):
    #x = 1. * x / (torch.norm(x, 2, axis, keepdim=True).expand_as(x) + 1e-12)
    #return x

def _euclidean_metric(a, b, normalize=False):
    if normalize:
        a = F.normalize(a)
        b = F.normalize(b)
    n = a.shape[0]
    m = b.shape[0]
    a = a.unsqueeze(1).expand(n, m, -1)
    b = b.unsqueeze(0).expand(n, m, -1)
    #print(a.shape)
    #print(b.shape)

    #logits = -((a - b) ** 2).sum(dim=2)
    #logits = -torch.norm(a-b, p=1,dim=2)   #manhatan distance
    logits = -torch.norm(a-b, p=3,dim=2)

    #a =a.mean(dim=0, keepdims=True)
    #b =b.mean(dim=0, keepdims=True)
    #logits = torch.cosine_similarity(a.unsqueeze(1), b.unsqueeze(0), dim=-1)
    #pdist = torch.nn.PairwiseDistance(p=2)
    #logits = pdist(a,b)

    #cos = torch.nn.CosineSimilarity(dim=-1, eps=1e-6)
    #logits = cos(a,b)

    #a,b=normalize(a),normalize(b)
    #logits = cos=1-torch.mm(a,b.permute(1,0))
    #print(logits.shape)

    #logits = -(1-torch.cosine_similarity(a, b, dim=-1))   #cosine similarity
    #print(logits)

    #logits = torch.cdist(a,b,p=2)
    #print(logits.shape)

    #logits = pairwise_manhattan_distance(a, b)
    #print(logits.shape)

    return logits

import argparse
import logging
import os
import torch

#import torch.nn.functional as F
import numpy as np

from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score

device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

preds = None
emissions = None
out_label_ids = None
preds_ls = []
emission_ls = []
out_label_ids_ls = []

for i in range(len(path_list_labels)):
    embed_filename = path_list[i]
    target_filename = path_list_labels[i]
    encodings = torch.load(os.path.join(path,embed_filename))
    labels = torch.load(os.path.join(path1,target_filename))

    #we need encodings, support_encodings, support_IO_labels from SANER!
    nn_preds, nn_emissions = nn_decode(encodings, support_encodings, support_IO_labels)
    if preds is None:
        preds = nn_preds.detach().cpu().numpy()
        emissions = nn_emissions.detach().cpu().numpy()
        out_label_ids = labels.detach().cpu().numpy()
        preds_ls.append(preds.reshape(-1))
        emission_ls.append(emissions.reshape(-1))
        out_label_ids_ls.append(out_label_ids.reshape(-1))
    else:
        preds_ls.append(nn_preds.detach().cpu().numpy().reshape(-1))
        emission_ls.append(nn_emissions.detach().cpu().numpy().reshape(-1))
        out_label_ids_ls.append(labels.detach().cpu().numpy().reshape(-1))

print(len(preds_ls))

out_label_list = [[] for _ in range(len(out_label_ids_ls))]
preds_list = [[] for _ in range(len(out_label_ids_ls))]

for i in range(len(out_label_ids_ls)):
  for j in range(out_label_ids_ls[i].shape[0]):
    out_label_list[i].append(label_map[out_label_ids_ls[i][j]])
    preds_list[i].append(IO_label_map[preds_ls[i][j]])

"""**[NOTE10]** Finally, we will get the results."""

print(preds_ls)

from seqeval.metrics import accuracy_score, f1_score, precision_score, recall_score

results = {
    "precision": precision_score(out_label_list, preds_list),
    "recall": recall_score(out_label_list, preds_list),
    "f1": f1_score(out_label_list, preds_list),
}
print(results)

"""find most similar words"""

import gensim
from nltk.corpus import brown
model = gensim.models.Word2Vec(brown.sents())
model.most_similar(positive=['drug'], topn = 10)

model.most_similar(positive=['patient'], topn = 10)

print(brown.sents())

mimic_sents = []
tmp =[]

with open("/content/SANER/data/sampleSet/train.txt","r") as f:
  text = f.readlines()
  for line in text:
    new_line = line.strip("\n").split(" ")
    #print(new_line[0])
    tmp.append(new_line[0])
    if(line=="\n"):
      mimic_sents.append(tmp)
      tmp = []

print(mimic_sents)

import gensim
from nltk.corpus import brown
model = gensim.models.Word2Vec(mimic_sents)
#model.most_similar(positive=['drug'], topn = 10)

model.most_similar(positive=['to'], topn = 10)

import gensim.downloader
glove_vectors = gensim.downloader.load('glove-twitter-25')
glove_vectors.most_similar('twitter')

glove_vectors.most_similar('diarrhea')